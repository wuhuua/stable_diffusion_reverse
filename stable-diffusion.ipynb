{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "697bcd71",
   "metadata": {
    "_kg_hide-input": true,
    "execution": {
     "iopub.execute_input": "2023-03-08T15:07:26.699103Z",
     "iopub.status.busy": "2023-03-08T15:07:26.697915Z",
     "iopub.status.idle": "2023-03-08T15:07:26.712352Z",
     "shell.execute_reply": "2023-03-08T15:07:26.711415Z"
    },
    "papermill": {
     "duration": 0.023112,
     "end_time": "2023-03-08T15:07:26.714688",
     "exception": false,
     "start_time": "2023-03-08T15:07:26.691576",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Args(object):\n",
    "    def __init__(self, model_name, train_path, dev_path, test_path, add_eos_token_to_data, margin, max_len,\n",
    "                number_of_gpu, batch_size_per_gpu, gradient_accumulation_steps, effective_batch_size, total_steps, \n",
    "                 print_every, save_every, learning_rate, save_path_prefix):\n",
    "        self.model_name = model_name\n",
    "        self.train_path = train_path\n",
    "        self.dev_path = dev_path\n",
    "        self.test_path = test_path\n",
    "        self.add_eos_token_to_data = add_eos_token_to_data\n",
    "        self.margin = margin\n",
    "        self.max_len = max_len  \n",
    "        self.number_of_gpu = number_of_gpu\n",
    "        self.batch_size_per_gpu = batch_size_per_gpu\n",
    "        self.gradient_accumulation_steps = gradient_accumulation_steps\n",
    "        self.effective_batch_size = effective_batch_size\n",
    "        self.total_steps = total_steps\n",
    "        self.print_every = print_every\n",
    "        self.save_every = save_every\n",
    "        self.learning_rate = learning_rate\n",
    "        self.save_path_prefix = save_path_prefix\n",
    "        self.max_grad_norm = 1.0\n",
    "args = Args('gpt2', \"/kaggle/input/flickr30k/flickr30k/flickr30k/flickr30k_train.json\",\n",
    "           \"/kaggle/input/flickr30k/flickr30k/flickr30k/flickr30k_val.json\", \n",
    "           \"/kaggle/input/flickr30k/flickr30k/flickr30k/flickr30k_test.json\",\n",
    "           'True', 0.5, 64, 1, 32, 4, 128, 10000, 50, 250, 2e-5, \"/kaggle/working/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9a0d5fcd",
   "metadata": {
    "_kg_hide-input": true,
    "execution": {
     "iopub.execute_input": "2023-03-08T15:07:26.723436Z",
     "iopub.status.busy": "2023-03-08T15:07:26.723136Z",
     "iopub.status.idle": "2023-03-08T15:07:29.115292Z",
     "shell.execute_reply": "2023-03-08T15:07:29.114232Z"
    },
    "papermill": {
     "duration": 2.399494,
     "end_time": "2023-03-08T15:07:29.117812",
     "exception": false,
     "start_time": "2023-03-08T15:07:26.718318",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#dataclass.py\n",
    "import json\n",
    "import random\n",
    "import torch\n",
    "import numpy as np\n",
    "import progressbar\n",
    "from torch.nn.utils import rnn\n",
    "\n",
    "class Data:\n",
    "    def __init__(self, model_name, train_path, dev_path, test_path, max_len, \n",
    "        sos_token, pad_token, add_eos_token_to_data):\n",
    "        '''\n",
    "            model_name: gpt2\n",
    "            train_path: training data path\n",
    "            dev_path: validation data path\n",
    "            test_path: test data path \n",
    "            max_len: maximum length for training sequences \n",
    "            sos_token: initialized sos token <-start_of_text->\n",
    "            pad_token: used to pad the sequences <-pad->\n",
    "            add_eos_token_to_data: whether we want to the model learn to generate eos token;\n",
    "                if so, the model could automatically stop generation by generating eos token\n",
    "        '''\n",
    "        from transformers import GPT2TokenizerFast\n",
    "        self.tokenizer = GPT2TokenizerFast.from_pretrained(model_name)\n",
    "        self.sos_token, self.sos_token_id = self.add_special_token(sos_token)\n",
    "        print ('sos token is {}, sos token id is {}'.format(self.sos_token, self.sos_token_id))\n",
    "        self.pad_token, self.pad_token_id = self.add_special_token(pad_token)\n",
    "        print ('pad token is {}, pad token id is {}'.format(self.pad_token, self.pad_token_id))\n",
    "        self.eos_token, self.eos_token_id = self.tokenizer.bos_token, self.tokenizer.bos_token_id\n",
    "        print ('eos token is {}, eos token id is {}'.format(self.eos_token, self.eos_token_id))\n",
    "        self.add_eos_token_to_data = add_eos_token_to_data\n",
    "\n",
    "        self.max_len = max_len\n",
    "        self.train_token_list, self.train_token_id_list = self.process_one_file(train_path)\n",
    "        self.dev_token_list, self.dev_token_id_list = self.process_one_file(dev_path)\n",
    "        self.test_token_list, self.test_token_id_list = self.process_one_file(test_path)\n",
    "        self.train_num, self.dev_num, self.test_num = len(self.train_token_list), len(self.dev_token_list), \\\n",
    "        len(self.test_token_list)\n",
    "        print ('train number:{}, dev number:{}, test number:{}'.format(self.train_num, self.dev_num, self.test_num))\n",
    "\n",
    "        self.train_idx_list = [i for i in range(self.train_num)]\n",
    "        random.shuffle(self.train_idx_list)\n",
    "        self.dev_idx_list = [j for j in range(self.dev_num)]\n",
    "        self.test_idx_list = [j for j in range(self.test_num)]\n",
    "        self.dev_current_idx, self.test_current_idx = 0, 0\n",
    "\n",
    "    def add_special_token(self, special_token):\n",
    "        if special_token in self.tokenizer.vocab:\n",
    "            print (special_token + ' token exists.')\n",
    "        else:\n",
    "            print ('Add token to the tokenizer.')\n",
    "            print ('Original vocabulary size is {}'.format(len(self.tokenizer)))\n",
    "            self.tokenizer.add_tokens([special_token])\n",
    "            print ('Vocabulary size after extension is {}'.format(len(self.tokenizer)))\n",
    "            assert len(self.tokenizer.convert_tokens_to_ids([special_token])) == 1\n",
    "        special_token_id = self.tokenizer.convert_tokens_to_ids([special_token])[0]\n",
    "        return special_token, special_token_id\n",
    "\n",
    "    def process_one_file(self, path):\n",
    "        print ('Processing {}'.format(path))\n",
    "        with open(path) as f:\n",
    "            item_list = json.load(f)\n",
    "        lines = []\n",
    "        for item in item_list:\n",
    "            captions_list = item['captions']\n",
    "            for one_caption in captions_list:\n",
    "                lines.append(one_caption.strip())\n",
    "\n",
    "        res_token_list, res_token_id_list = [], []\n",
    "        n = len(lines)\n",
    "        p = progressbar.ProgressBar(n)\n",
    "        p.start()\n",
    "        for i in range(n):\n",
    "            p.update(i)\n",
    "            text = lines[i].strip('\\n')\n",
    "            self.process_one_text(text, res_token_list, res_token_id_list)\n",
    "        p.finish()\n",
    "        print ('{} processed!'.format(path))\n",
    "        return res_token_list, res_token_id_list\n",
    "\n",
    "    def process_one_text(self, text, res_token_list, res_token_id_list):\n",
    "        tokens = self.tokenizer.tokenize(text, max_length=self.max_len, truncation=True)\n",
    "        if len(tokens) <= 1: # filter out too short sequence\n",
    "            return\n",
    "        tokens = [self.sos_token] + tokens[:self.max_len]\n",
    "        if self.add_eos_token_to_data:\n",
    "            tokens = tokens + [self.eos_token]\n",
    "        token_ids = self.tokenizer.convert_tokens_to_ids(tokens)\n",
    "        res_token_list.append(tokens)\n",
    "        res_token_id_list.append(token_ids)\n",
    "        return\n",
    "\n",
    "    def pad_batch(self, batch_id_list):\n",
    "        batch_id_list = [torch.LongTensor(item) for item in batch_id_list]\n",
    "        batch_tensor = rnn.pad_sequence(batch_id_list, batch_first=True, padding_value=self.pad_token_id)\n",
    "        batch_mask = torch.ones_like(batch_tensor)\n",
    "        batch_mask = batch_mask.masked_fill(batch_tensor.eq(self.pad_token_id), 0.0).type(torch.FloatTensor)\n",
    "        return batch_tensor, batch_mask\n",
    "\n",
    "    def process_output(self, batch_tgt_id_list):\n",
    "        batch_tgt_id_list = [torch.LongTensor(item) for item in batch_tgt_id_list]\n",
    "        batch_tgt_tensor, _ = self.pad_batch(batch_tgt_id_list) # padded target sequence\n",
    "        batch_tgt_input_tensor = batch_tgt_tensor[:, :-1].clone()\n",
    "        batch_tgt_output_tensor = batch_tgt_tensor[:, 1:].clone()\n",
    "        return batch_tgt_input_tensor, batch_tgt_output_tensor\n",
    "\n",
    "    def parse_batch(self, batch_id_list):\n",
    "        batch_input, batch_labels = self.process_output(batch_id_list)\n",
    "        batch_labels[batch_labels[:, :] == self.pad_token_id] = -100\n",
    "        return batch_input, batch_labels\n",
    "\n",
    "    def get_next_train_batch(self, batch_size):\n",
    "        batch_idx_list = random.sample(self.train_idx_list, batch_size)\n",
    "        batch_id_list, batch_token_list = [], []\n",
    "\n",
    "        for idx in batch_idx_list:\n",
    "            batch_id_list.append(self.train_token_id_list[idx])\n",
    "            batch_token_list.append(self.train_token_list[idx])\n",
    "        batch_input_tensor, batch_labels = self.parse_batch(batch_id_list)\n",
    "        return batch_input_tensor, batch_labels, batch_token_list\n",
    "\n",
    "    def get_next_validation_batch(self, batch_size, mode):\n",
    "        batch_id_list, batch_token_list = [], []\n",
    "        if mode == 'dev':\n",
    "            curr_select_idx, instance_num = self.dev_current_idx, self.dev_num\n",
    "            tgt_token_id_list, tgt_token_list = self.dev_token_id_list, self.dev_token_list\n",
    "        elif mode == 'test':\n",
    "            curr_select_idx, instance_num = self.test_current_idx, self.test_num\n",
    "            tgt_token_id_list, tgt_token_list = self.test_token_id_list, self.test_token_list\n",
    "        else:\n",
    "            raise Exception('Wrong Validation Mode!!!')\n",
    "\n",
    "        if curr_select_idx + batch_size < instance_num:\n",
    "            for i in range(batch_size):\n",
    "                curr_idx = curr_select_idx + i\n",
    "                batch_id_list.append(tgt_token_id_list[curr_idx])\n",
    "                batch_token_list.append(tgt_token_list[curr_idx])\n",
    "            if mode == 'dev':\n",
    "                self.dev_current_idx += batch_size\n",
    "            else:\n",
    "                self.test_current_idx += batch_size\n",
    "        else:\n",
    "            for i in range(batch_size):\n",
    "                curr_idx = curr_select_idx + i\n",
    "                if curr_idx > instance_num - 1: \n",
    "                    curr_idx = 0\n",
    "                    if mode == 'dev':\n",
    "                        self.dev_current_idx = 0\n",
    "                    else:\n",
    "                        self.test_current_idx = 0\n",
    "                batch_id_list.append(tgt_token_id_list[curr_idx])\n",
    "                batch_token_list.append(tgt_token_list[curr_idx])\n",
    "            if mode == 'dev':\n",
    "                self.dev_current_idx = 0\n",
    "            else:\n",
    "                self.test_current_idx = 0\n",
    "        batch_input_tensor, batch_labels = self.parse_batch(batch_id_list)\n",
    "        return batch_input_tensor, batch_labels, batch_token_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2204979a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-08T15:07:29.126917Z",
     "iopub.status.busy": "2023-03-08T15:07:29.126481Z",
     "iopub.status.idle": "2023-03-08T15:07:29.171377Z",
     "shell.execute_reply": "2023-03-08T15:07:29.170342Z"
    },
    "papermill": {
     "duration": 0.051863,
     "end_time": "2023-03-08T15:07:29.173435",
     "exception": false,
     "start_time": "2023-03-08T15:07:29.121572",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import operator\n",
    "from operator import itemgetter\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "import random\n",
    "import numpy as np\n",
    "import argparse\n",
    "import random\n",
    "\n",
    "def parse_prompt(text):\n",
    "    '''\n",
    "        process the prompt text;\n",
    "    '''\n",
    "    eos_token = '<|endoftext|>'\n",
    "    text = text.strip(eos_token).strip()\n",
    "    left_bracket_idx, right_bracket_idx = -1, -1\n",
    "    for idx in range(len(text)):\n",
    "        char = text[idx]\n",
    "        if char == '[' and left_bracket_idx == -1: # first [ is met\n",
    "            left_bracket_idx = idx\n",
    "        elif char == ']' and right_bracket_idx == -1: # first ] is met\n",
    "            right_bracket_idx = idx\n",
    "        else:\n",
    "            pass\n",
    "    res_text = ''\n",
    "    remove = False\n",
    "    if left_bracket_idx > -1 and right_bracket_idx > left_bracket_idx:\n",
    "        if right_bracket_idx - left_bracket_idx <= 6:\n",
    "            remove = True\n",
    "        else:\n",
    "            pass\n",
    "\n",
    "    for idx in range(len(text)):\n",
    "        if remove:\n",
    "            if idx >= left_bracket_idx and idx <= right_bracket_idx:\n",
    "                continue\n",
    "            else:\n",
    "                res_text += text[idx]\n",
    "        else:\n",
    "            res_text += text[idx]\n",
    "    res_text = res_text.strip()\n",
    "    res_text = ' '.join(res_text.split()).strip()\n",
    "    return res_text\n",
    "\n",
    "def typical_filtering(scores, mass, min_tokens_to_keep, filter_value):\n",
    "    # calculate entropy\n",
    "    normalized = torch.nn.functional.log_softmax(scores, dim=-1)\n",
    "    p = torch.exp(normalized)\n",
    "    ent = -(normalized * p).nansum(-1, keepdim=True)\n",
    "\n",
    "    # shift and sort\n",
    "    shifted_scores = torch.abs((-normalized) - ent)\n",
    "    sorted_scores, sorted_indices = torch.sort(shifted_scores, descending=False)\n",
    "    sorted_logits = scores.gather(-1, sorted_indices)\n",
    "    cumulative_probs = sorted_logits.softmax(dim=-1).cumsum(dim=-1)\n",
    "\n",
    "    # Remove tokens with cumulative mass above the threshold\n",
    "    last_ind = (cumulative_probs < mass).sum(dim=1)\n",
    "    last_ind[last_ind < 0] = 0\n",
    "    sorted_indices_to_remove = sorted_scores > sorted_scores.gather(1, last_ind.view(-1, 1))\n",
    "    if min_tokens_to_keep > 1:\n",
    "        # Keep at least min_tokens_to_keep (set to min_tokens_to_keep-1 because we add the first one below)\n",
    "        sorted_indices_to_remove[..., : min_tokens_to_keep] = 0\n",
    "    indices_to_remove = sorted_indices_to_remove.scatter(1, sorted_indices, sorted_indices_to_remove)\n",
    "\n",
    "    scores = scores.masked_fill(indices_to_remove, filter_value)\n",
    "    return scores\n",
    "\n",
    "def top_k_top_p_filtering(logits, top_k=0, top_p=0.0, threshold=-float('Inf'), filter_value=-np.inf):\n",
    "    assert logits.dim() == 1\n",
    "    top_k = min(top_k, logits.size(-1))\n",
    "    if top_k > 0:\n",
    "        indices_to_remove = logits < torch.topk(logits, top_k)[0][..., -1, None]\n",
    "        logits[indices_to_remove] = filter_value\n",
    "    if top_p > 0.0:\n",
    "        sorted_logits, sorted_indices = torch.sort(logits, descending=True)\n",
    "        cumulative_probs = torch.cumsum(F.softmax(sorted_logits, dim=-1), dim=-1)\n",
    "        sorted_indices_to_remove = cumulative_probs > top_p\n",
    "        sorted_indices_to_remove[..., 1:] = sorted_indices_to_remove[..., :-1].clone()\n",
    "        sorted_indices_to_remove[..., 0] = 0\n",
    "\n",
    "        indices_to_remove = sorted_indices[sorted_indices_to_remove]\n",
    "        logits[indices_to_remove] = filter_value\n",
    "        \n",
    "    indices_to_remove = logits < threshold\n",
    "    logits[indices_to_remove] = filter_value\n",
    "    return logits\n",
    "\n",
    "# ========== batch version ========= #\n",
    "def ranking_fast(context_hidden, next_hidden, next_top_k_probs, alpha, beam_width):\n",
    "    '''\n",
    "        context_hidden: bsz*beam x seqlen x embed_dim\n",
    "        next_hidden: bsz*beam x 1 x embed_dim\n",
    "        next_top_k_probs: bsz x beam\n",
    "    '''\n",
    "    _, context_len, embed_dim = context_hidden.size()\n",
    "    norm_context_hidden = context_hidden / context_hidden.norm(dim=2, keepdim=True)\n",
    "    norm_next_hidden = next_hidden / next_hidden.norm(dim=2, keepdim=True)\n",
    "    cosine_matrix = torch.matmul(norm_context_hidden, norm_next_hidden.transpose(1,2)).squeeze(-1)    # [B*K, S]\n",
    "    scores, _ = torch.max(cosine_matrix, dim=-1)    # [B*K]\n",
    "    next_top_k_probs = next_top_k_probs.view(-1)    # [B*K]\n",
    "    scores = (1.0 - alpha) * next_top_k_probs - alpha * scores \n",
    "    scores = torch.stack(torch.split(scores, beam_width))    # [B, K]\n",
    "    selected_idx = scores.max(dim=-1)[1]    # [B]\n",
    "    return selected_idx\n",
    "\n",
    "def ContrastiveDecodingOneStepFast(\n",
    "    model, \n",
    "    ids, \n",
    "    beam_width, \n",
    "    alpha, \n",
    "    past_key_values,\n",
    "    last_hidden_states,\n",
    "    vocab,\n",
    "    logit_for_next_step,\n",
    "    first_step=False,\n",
    "    ):\n",
    "    # input_ids: [B, S]\n",
    "    if first_step:\n",
    "        output = model(\n",
    "            input_ids=ids, \n",
    "            past_key_values=past_key_values,\n",
    "            use_cache=True,\n",
    "            output_hidden_states=True\n",
    "        )\n",
    "        past_key_values = output.past_key_values\n",
    "        last_hidden_states = output.hidden_states[-1]    # [B, S, E]\n",
    "        logit_for_next_step = output.logits[:, -1, :]    # [B, V]\n",
    "    bsz, seqlen, embed_dim = last_hidden_states.size()\n",
    "    p = random.uniform(0, 1)\n",
    "\n",
    "    next_probs = F.softmax(logit_for_next_step, dim=-1)\n",
    "    _, top_k_ids = torch.topk(logit_for_next_step, dim=-1, k=beam_width)    # [B, K]\n",
    "    top_k_probs = torch.gather(next_probs, dim=1, index=top_k_ids)    # [B, K]\n",
    "    # compute new hidden\n",
    "    past_key_values = enlarge_past_key_values(past_key_values, beam_width)\n",
    "    output = model(\n",
    "        input_ids=top_k_ids.view(-1, 1), \n",
    "        attention_mask=torch.ones_like(top_k_ids.view(-1, 1)),\n",
    "        past_key_values=past_key_values,\n",
    "        output_hidden_states=True,\n",
    "        use_cache=True,\n",
    "    )\n",
    "    past_key_values = output.past_key_values\n",
    "    logits = output.logits[:, -1, :]    # [B*K, V]\n",
    "    next_hidden = output.hidden_states[-1]    # [B*K, 1, E]\n",
    "    context_hidden = last_hidden_states.unsqueeze(1).expand(-1, beam_width, -1, -1).reshape(bsz*beam_width, seqlen, embed_dim)    # [B*K, S, E]\n",
    "\n",
    "    selected_idx = ranking_fast(\n",
    "        context_hidden, \n",
    "        next_hidden, \n",
    "        top_k_probs,    # [B, K] \n",
    "        alpha,\n",
    "        beam_width,\n",
    "    )     # [B]\n",
    "    # prepare for the next step\n",
    "    next_id = top_k_ids[range(len(top_k_ids)), selected_idx].unsqueeze(-1)    # [B, 1]\n",
    "    next_hidden = torch.stack(torch.split(next_hidden.squeeze(dim=1), beam_width))    # [B, K, E]\n",
    "    next_hidden = next_hidden[range(bsz), selected_idx, :]    # [B, E]\n",
    "    last_hidden_states = torch.cat([last_hidden_states, next_hidden.unsqueeze(1)], dim=1)    # [B, S, E]\n",
    "    past_key_values = select_past_key_values(past_key_values, beam_width, selected_idx)\n",
    "    logits = torch.stack(torch.split(logits, beam_width))[range(bsz), selected_idx, :]    # [B, V]\n",
    "    # next_id: [B, 1]\n",
    "    return next_id, past_key_values, last_hidden_states, logits \n",
    "\n",
    "def enlarge_past_key_values(past_key_values, beam_width):\n",
    "    # from [B, num_head, seq_len, esz] to [B*K, num_head, seq_len, esz]\n",
    "    new_key_values = []\n",
    "    for layer in past_key_values:\n",
    "        items = []\n",
    "        for item in layer:\n",
    "            # item is the key and value matrix\n",
    "            bsz, num_head, seq_len, esz = item.size()\n",
    "            item = item.unsqueeze(1).expand(-1, beam_width, -1, -1, -1).reshape(bsz*beam_width, num_head, seq_len, esz)    # [bsz*beam, num_head, seq_len, esz]\n",
    "            items.append(item)\n",
    "        new_key_values.append(items)\n",
    "    return new_key_values\n",
    "\n",
    "def select_past_key_values(past_key_values, beam_width, selected_idx):\n",
    "    '''select_idx: [B]'''\n",
    "    new_key_values = []\n",
    "    for layer in past_key_values:\n",
    "        items = []\n",
    "        for item in layer:\n",
    "            bsz_and_beam, num_head, seq_len, esz = item.size()\n",
    "            bsz = int(bsz_and_beam//beam_width)\n",
    "            item = torch.stack(torch.split(item, beam_width, dim=0))    # [B, K, num_head, seq_len, esz] \n",
    "            item = item[range(bsz), selected_idx, :, :, :]   # [B, num_head, seq_len, esz]\n",
    "            items.append(item)\n",
    "        new_key_values.append(items)\n",
    "    return new_key_values\n",
    "\n",
    "# ========== fast plug and play version ========= #\n",
    "def plug_and_play_fast_ranking(\n",
    "    context_hidden, \n",
    "    next_hidden, \n",
    "    next_top_k_ids, \n",
    "    next_top_k_probs, \n",
    "    alpha, \n",
    "    beta, \n",
    "    batch_class_score,\n",
    "    beam_width,\n",
    "):\n",
    "    '''\n",
    "        context_hidden: beam_width x context_len x embed_dim\n",
    "        next_hidden: beam_width x 1 x embed_dim\n",
    "        next_top_k_ids: beam_width x 1\n",
    "        batch_class_score: beam_width x 1\n",
    "    '''\n",
    "    _, context_len, embed_dim = context_hidden.size()\n",
    "    norm_context_hidden = context_hidden / context_hidden.norm(dim=2, keepdim=True)\n",
    "    norm_next_hidden = next_hidden / next_hidden.norm(dim=2, keepdim=True)\n",
    "    cosine_matrix = torch.matmul(norm_context_hidden, norm_next_hidden.transpose(1,2)).squeeze(-1)\n",
    "    scores, _ = torch.max(cosine_matrix, dim = -1)\n",
    "    next_top_k_probs = next_top_k_probs.view(-1)\n",
    "    scores = (1.0 - alpha) * next_top_k_probs - alpha * scores + beta * batch_class_score.view([beam_width])\n",
    "    scores = torch.stack(torch.split(scores, beam_width))\n",
    "    selected_idx = scores.max(dim=-1)[1]\n",
    "    return selected_idx\n",
    "\n",
    "def PlugAndPlayContrastiveDecodingOneStepFast(model, input_ids, prefix_len, beam_width, alpha, beta, \n",
    "    simctg_tokenizer, image_embeds, clip, clip_text_max_len, past_key_values, last_hidden_states, \n",
    "    logit_for_next_step, first_step=False, input_ids_for_class=None):#, add_token_level_score=False):\n",
    "    '''\n",
    "        model: the generation model, e.g., gpt2\n",
    "        input_ids: 1 x seqlen\n",
    "    '''\n",
    "\n",
    "    if first_step:\n",
    "        output = model(input_ids=input_ids, past_key_values=past_key_values, use_cache=True, output_hidden_states=True)\n",
    "        past_key_values = output.past_key_values\n",
    "        last_hidden_states = output.hidden_states[-1]    # [B, S, E]\n",
    "        logit_for_next_step = output.logits[:, -1, :]    # [B, V]\n",
    "    bsz, seqlen, embed_dim = last_hidden_states.size()\n",
    "    next_probs = F.softmax(logit_for_next_step, dim = -1)\n",
    "    _, top_k_ids = torch.topk(logit_for_next_step, dim = -1, k = beam_width)\n",
    "    top_k_probs = torch.gather(next_probs, dim = 1, index=top_k_ids)\n",
    "\n",
    "    # compute the new hidden\n",
    "    past_key_values = enlarge_past_key_values(past_key_values, beam_width)\n",
    "    output = model(\n",
    "        input_ids=top_k_ids.view(-1, 1) ,\n",
    "        attention_mask=torch.ones_like(top_k_ids.view(-1, 1)),\n",
    "        past_key_values=past_key_values,\n",
    "        output_hidden_states=True,\n",
    "        use_cache=True,\n",
    "    )\n",
    "    past_key_values = output.past_key_values\n",
    "    logits = output.logits[:, -1, :]\n",
    "    next_hidden = output.hidden_states[-1]\n",
    "    context_hidden = last_hidden_states.unsqueeze(1).expand(-1, beam_width, -1, -1).reshape(bsz*beam_width, seqlen, embed_dim)\n",
    "    \n",
    "    # prepare for the classification model\n",
    "    input_ids_for_class_ = torch.cat([\n",
    "        input_ids_for_class.unsqueeze(1).expand(-1, beam_width, -1).reshape(bsz*beam_width, seqlen),\n",
    "        top_k_ids.view(-1, 1)\n",
    "        ], dim=-1\n",
    "    )\n",
    "\n",
    "    batch_text_list = []\n",
    "    for one_input_id in input_ids_for_class_:\n",
    "        one_text = simctg_tokenizer.decode(one_input_id[prefix_len:][-clip_text_max_len:]) \n",
    "        # we only consider the class score of the generated text continuation\n",
    "        batch_text_list.append(one_text)\n",
    "    batch_score = clip.compute_image_text_similarity_via_raw_text(image_embeds, batch_text_list)\n",
    "\n",
    "    selected_idx = plug_and_play_fast_ranking(\n",
    "        context_hidden, \n",
    "        next_hidden, \n",
    "        top_k_ids, \n",
    "        top_k_probs, \n",
    "        alpha, \n",
    "        beta, \n",
    "        batch_score,\n",
    "        beam_width,\n",
    "    )       \n",
    "\n",
    "    # prepare for the next step\n",
    "    next_id = top_k_ids[range(len(top_k_ids)), selected_idx].unsqueeze(-1)\n",
    "    next_hidden = torch.stack(torch.split(next_hidden.squeeze(dim=1), beam_width))\n",
    "    next_hidden = next_hidden[range(bsz), selected_idx, :]\n",
    "    last_hidden_states = torch.cat([last_hidden_states, next_hidden.unsqueeze(1)], dim=1)\n",
    "    past_key_values = select_past_key_values(past_key_values, beam_width, selected_idx)\n",
    "    logits = torch.stack(torch.split(logits, beam_width))[range(bsz), selected_idx, :]\n",
    "    input_ids_for_class = torch.cat([input_ids_for_class, next_id], dim=-1)\n",
    "    return next_id, past_key_values, last_hidden_states, logits, input_ids_for_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bf359c5a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-08T15:07:29.181871Z",
     "iopub.status.busy": "2023-03-08T15:07:29.181594Z",
     "iopub.status.idle": "2023-03-08T15:07:29.206378Z",
     "shell.execute_reply": "2023-03-08T15:07:29.205391Z"
    },
    "papermill": {
     "duration": 0.031778,
     "end_time": "2023-03-08T15:07:29.208557",
     "exception": false,
     "start_time": "2023-03-08T15:07:29.176779",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#trainer.py\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.multiprocessing as mp\n",
    "import argparse, os\n",
    "import random\n",
    "import numpy as np\n",
    "import time\n",
    "import logging\n",
    "import progressbar\n",
    "\n",
    "import logging\n",
    "logging.getLogger('transformers.generation_utils').disabled = True\n",
    "\n",
    "def eval_model(args, model, data, cuda_available, device):\n",
    "    dataset_batch_size = args.batch_size_per_gpu * args.number_of_gpu\n",
    "    eval_step = int(data.test_num / dataset_batch_size) + 1\n",
    "    val_loss, token_sum = 0., 0.\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        p = progressbar.ProgressBar(eval_step)\n",
    "        p.start()\n",
    "        for idx in range(eval_step):\n",
    "            p.update(idx)\n",
    "            batch_input_tensor, batch_labels, _ = \\\n",
    "            data.get_next_validation_batch(batch_size=dataset_batch_size, mode='test')\n",
    "            if cuda_available:\n",
    "                batch_input_tensor = batch_input_tensor.cuda(device)\n",
    "                batch_labels = batch_labels.cuda(device)\n",
    "            one_val_loss, one_val_token_sum = model.eval_loss(batch_input_tensor, batch_labels)\n",
    "            one_val_loss = torch.sum(one_val_loss)\n",
    "            one_val_token_sum = torch.sum(one_val_token_sum)\n",
    "            val_loss += one_val_loss.item()\n",
    "            token_sum += one_val_token_sum.item()\n",
    "        p.finish()\n",
    "    model.train()\n",
    "    val_loss = val_loss / token_sum\n",
    "    return val_loss\n",
    "\n",
    "def model_training(args, data, model, total_steps, print_every, save_every, ckpt_save_path, cuda_available, device):\n",
    "    import os\n",
    "    if os.path.exists(ckpt_save_path):\n",
    "        pass\n",
    "    else: # recursively construct directory\n",
    "        os.makedirs(ckpt_save_path, exist_ok=True)\n",
    "\n",
    "    max_save_num = 1\n",
    "\n",
    "    batch_size_per_gpu, gradient_accumulation_steps, number_of_gpu, effective_batch_size = \\\n",
    "    args.batch_size_per_gpu, args.gradient_accumulation_steps, args.number_of_gpu, args.effective_batch_size\n",
    "    assert effective_batch_size == batch_size_per_gpu * gradient_accumulation_steps * number_of_gpu\n",
    "\n",
    "    warmup_steps = int(0.1 * total_steps) # 10% of training steps are used for warmup\n",
    "    print ('total training steps is {}, warmup steps is {}'.format(total_steps, warmup_steps))\n",
    "    from transformers.optimization import AdamW, get_linear_schedule_with_warmup\n",
    "    optimizer = AdamW(model.parameters(), lr=args.learning_rate)\n",
    "    scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=warmup_steps, num_training_steps=total_steps)\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    effective_batch_acm = 0\n",
    "    all_batch_step = 1\n",
    "    print_valid, save_valid = False, False\n",
    "    train_loss, train_cl_loss, min_val_loss = 0., 0., 1e10\n",
    "    train_ave_bleu = 0.\n",
    "\n",
    "    print ('--------------------------------------------------------------------------')\n",
    "    print ('Start Training:')\n",
    "    model.train()\n",
    "    number_of_saves = 0\n",
    "\n",
    "    while effective_batch_acm < total_steps:\n",
    "        all_batch_step += 1\n",
    "        train_batch_input_tensor, train_batch_labels, _ = data.get_next_train_batch(batch_size_per_gpu * number_of_gpu)\n",
    "        if cuda_available:\n",
    "            train_batch_input_tensor = train_batch_input_tensor.cuda(device)\n",
    "            train_batch_labels = train_batch_labels.cuda(device)\n",
    "        mle_loss, cl_loss = model(train_batch_input_tensor, train_batch_labels, args.margin)\n",
    "\n",
    "        loss = mle_loss + cl_loss\n",
    "        loss = loss.mean()\n",
    "        loss.backward()\n",
    "        train_loss += mle_loss.item()\n",
    "        train_cl_loss += cl_loss.item()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), args.max_grad_norm)\n",
    "\n",
    "        # parameter update\n",
    "        if all_batch_step % gradient_accumulation_steps == 0:\n",
    "            optimizer.step()\n",
    "            scheduler.step()\n",
    "            optimizer.zero_grad()\n",
    "            effective_batch_acm += 1\n",
    "            print_valid, save_valid = True, True\n",
    "\n",
    "        # print intermediate result\n",
    "        if effective_batch_acm % print_every == 0 and print_valid:\n",
    "            denominator = (effective_batch_acm - (number_of_saves * save_every)) * gradient_accumulation_steps\n",
    "            one_train_loss = train_loss / denominator\n",
    "            one_train_cl_loss = train_cl_loss / denominator\n",
    "            print ('At training steps {}, training MLE loss is {}, train CL loss is {}'.format(effective_batch_acm, \n",
    "                one_train_loss, one_train_cl_loss))\n",
    "            print_valid = False\n",
    "\n",
    "        # saving result\n",
    "        if effective_batch_acm % save_every == 0 and save_valid:\n",
    "            number_of_saves += 1\n",
    "\n",
    "            save_valid = False\n",
    "            one_train_loss = train_loss / (save_every * gradient_accumulation_steps)\n",
    "            one_train_cl_loss = train_cl_loss / (save_every * gradient_accumulation_steps)\n",
    "\n",
    "            model.eval()\n",
    "            one_val_loss = eval_model(args, model, data, cuda_available, device)\n",
    "            model.train()\n",
    "\n",
    "            print ('At training steps {}, training MLE loss is {}, train CL loss is {}, validation loss is {}'.format(effective_batch_acm, \n",
    "                one_train_loss, one_train_cl_loss, one_val_loss))\n",
    "\n",
    "            train_loss, train_cl_loss = 0., 0.\n",
    "\n",
    "            if one_val_loss < min_val_loss:\n",
    "                # in finetuning stage, we always save the model\n",
    "                min_val_loss = min(one_val_loss, min_val_loss)\n",
    "                print ('Saving model...')\n",
    "                one_val_ppl = np.exp(one_val_loss)\n",
    "                one_val_ppl = round(one_val_ppl, 3)\n",
    "                save_name = 'training_step_{}_train_mle_loss_{}_train_cl_loss_{}_dev_loss_{}_dev_ppl_{}'.format(effective_batch_acm,\n",
    "                round(one_train_loss,5), round(one_train_cl_loss,5), round(one_val_loss,5), one_val_ppl)\n",
    "\n",
    "                model_save_path = ckpt_save_path + '/' + save_name\n",
    "                import os\n",
    "                if os.path.exists(model_save_path):\n",
    "                    pass\n",
    "                else: # recursively construct directory\n",
    "                    os.makedirs(model_save_path, exist_ok=True)\n",
    "                if cuda_available and torch.cuda.device_count() > 1:\n",
    "                    model.module.save_model(model_save_path)\n",
    "                else:\n",
    "                    model.save_model(model_save_path)\n",
    "                print ('Model Saved!')\n",
    "\n",
    "                # --------------------------------------------------------------------------------------------- #\n",
    "                # removing extra checkpoints...\n",
    "                import os\n",
    "                from operator import itemgetter\n",
    "                fileData = {}\n",
    "                test_output_dir = ckpt_save_path\n",
    "                for fname in os.listdir(test_output_dir):\n",
    "                    if fname.startswith('training_step'):\n",
    "                        fileData[fname] = os.stat(test_output_dir + '/' + fname).st_mtime\n",
    "                    else:\n",
    "                        pass\n",
    "                sortedFiles = sorted(fileData.items(), key=itemgetter(1))\n",
    "\n",
    "                if len(sortedFiles) < max_save_num:\n",
    "                    pass\n",
    "                else:\n",
    "                    delete = len(sortedFiles) - max_save_num\n",
    "                    for x in range(0, delete):\n",
    "                        one_folder_name = test_output_dir + '/' + sortedFiles[x][0]\n",
    "                        os.system('rm -r ' + one_folder_name)\n",
    "                print ('-----------------------------------')\n",
    "                # --------------------------------------------------------------------------------------------- #\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "337383d5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-08T15:07:29.216818Z",
     "iopub.status.busy": "2023-03-08T15:07:29.216542Z",
     "iopub.status.idle": "2023-03-08T15:07:29.230554Z",
     "shell.execute_reply": "2023-03-08T15:07:29.229662Z"
    },
    "papermill": {
     "duration": 0.020633,
     "end_time": "2023-03-08T15:07:29.232643",
     "exception": false,
     "start_time": "2023-03-08T15:07:29.212010",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#loss_func.py\n",
    "import torch\n",
    "\n",
    "def compute_valid_token_num(valid_len_list):\n",
    "    res = 0\n",
    "    for one_len in valid_len_list:\n",
    "        res += one_len * (one_len - 1)\n",
    "    return res\n",
    "\n",
    "def build_mask_matrix(seqlen, valid_len_list, prefix_len = 0):\n",
    "    '''\n",
    "        prefix_len: the length of prefix that we do not want to compute CL loss for.\n",
    "        (1) if a sequence of length 4 contains zero padding token (i.e., the valid length is 4),\n",
    "            then the loss padding matrix looks like\n",
    "                 [0., 1., 1., 1.],\n",
    "                 [1., 0., 1., 1.],\n",
    "                 [1., 1., 0., 1.],\n",
    "                 [1., 1., 1., 0.]\n",
    "        (2) if a sequence of length 4 contains 1 padding token (i.e., the valid length is 3),\n",
    "            then the loss padding matrix looks like\n",
    "                 [0., 1., 1., 0.],\n",
    "                 [1., 0., 1., 0.],\n",
    "                 [1., 1., 0., 0.],\n",
    "                 [0., 0., 0., 0.]\n",
    "    '''\n",
    "    res_list = []\n",
    "    base_mask = torch.ones(seqlen, seqlen) - torch.eye(seqlen, seqlen)\n",
    "    base_mask = base_mask.type(torch.FloatTensor)\n",
    "    bsz = len(valid_len_list)\n",
    "    for i in range(bsz):\n",
    "        one_base_mask = base_mask.clone()\n",
    "        one_valid_len = valid_len_list[i]\n",
    "        one_base_mask[:,one_valid_len:] = 0.\n",
    "        one_base_mask[one_valid_len:, :] = 0.\n",
    "        if prefix_len > 0:\n",
    "            one_base_mask[:prefix_len, :prefix_len] = 0.\n",
    "        res_list.append(one_base_mask)\n",
    "    res_mask = torch.stack(res_list, dim = 0)#torch.FloatTensor(res_list)\n",
    "    #print (res_mask)\n",
    "    assert res_mask.size() == torch.Size([bsz, seqlen, seqlen])\n",
    "    return res_mask\n",
    "        \n",
    "def contrastive_loss(margin, score_matrix, input_ids, pad_token_id, prefix_len=0):\n",
    "    '''\n",
    "       margin: predefined margin to push similarity score away\n",
    "       score_matrix: bsz x seqlen x seqlen\n",
    "       input_ids: bsz x seqlen\n",
    "       pad_token_id: indicating which tokens are padding token\n",
    "    '''\n",
    "    bsz, seqlen, _ = score_matrix.size()\n",
    "    gold_score = torch.diagonal(score_matrix, offset=0, dim1=1, dim2=2) # bsz x seqlen\n",
    "    gold_score = torch.unsqueeze(gold_score, -1)\n",
    "    assert gold_score.size() == torch.Size([bsz, seqlen, 1])\n",
    "    difference_matrix = gold_score - score_matrix\n",
    "    assert difference_matrix.size() == torch.Size([bsz, seqlen, seqlen])\n",
    "    loss_matrix = margin - difference_matrix # bsz x seqlen x seqlen\n",
    "    loss_matrix = torch.nn.functional.relu(loss_matrix)\n",
    "\n",
    "    ### input mask\n",
    "    input_mask = torch.ones_like(input_ids).type(torch.FloatTensor)\n",
    "    if loss_matrix.is_cuda:\n",
    "        input_mask = input_mask.cuda(loss_matrix.get_device())\n",
    "    input_mask = input_mask.masked_fill(input_ids.eq(pad_token_id), 0.0)\n",
    "\n",
    "    if loss_matrix.is_cuda:\n",
    "        input_mask = input_mask.cuda(loss_matrix.get_device())\n",
    "\n",
    "    valid_len_list = torch.sum(input_mask, dim = -1).tolist()\n",
    "    loss_mask = build_mask_matrix(seqlen, [int(item) for item in valid_len_list], prefix_len)\n",
    "    if score_matrix.is_cuda:\n",
    "        loss_mask = loss_mask.cuda(score_matrix.get_device())\n",
    "    masked_loss_matrix = loss_matrix * loss_mask\n",
    "\n",
    "    loss_matrix = torch.sum(masked_loss_matrix, dim = -1)\n",
    "    assert loss_matrix.size() == input_ids.size()\n",
    "    loss_matrix = loss_matrix * input_mask\n",
    "    cl_loss = torch.sum(loss_matrix) / torch.sum(loss_mask)\n",
    "    return cl_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0530b4db",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-08T15:07:29.241142Z",
     "iopub.status.busy": "2023-03-08T15:07:29.240874Z",
     "iopub.status.idle": "2023-03-08T15:07:30.211658Z",
     "shell.execute_reply": "2023-03-08T15:07:30.210589Z"
    },
    "papermill": {
     "duration": 0.978345,
     "end_time": "2023-03-08T15:07:30.214405",
     "exception": false,
     "start_time": "2023-03-08T15:07:29.236060",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#simCTG.py\n",
    "import os\n",
    "import sys\n",
    "import operator\n",
    "from tqdm import tqdm\n",
    "from operator import itemgetter\n",
    "import torch\n",
    "from torch import nn\n",
    "import random\n",
    "import argparse\n",
    "import numpy as np\n",
    "import torch.nn.functional as F\n",
    "from torch.nn import CrossEntropyLoss\n",
    "#from loss_func import contrastive_loss\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import datetime\n",
    "\n",
    "train_fct = CrossEntropyLoss()\n",
    "val_fct = CrossEntropyLoss(reduction='none')\n",
    "class SimCTG(nn.Module):\n",
    "    def __init__(self, model_name, sos_token, pad_token):\n",
    "        super(SimCTG, self).__init__()\n",
    "        from transformers import AutoTokenizer, GPT2LMHeadModel\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "        self.sos_token, self.sos_token_id = self.add_special_token(sos_token)\n",
    "        print ('sos token is {}, sos token id is {}'.format(self.sos_token, self.sos_token_id))\n",
    "        self.pad_token, self.pad_token_id = self.add_special_token(pad_token)\n",
    "        print ('pad token is {}, pad token id is {}'.format(self.pad_token, self.pad_token_id))\n",
    "        self.eos_token, self.eos_token_id = self.tokenizer.bos_token, self.tokenizer.bos_token_id\n",
    "        print ('eos token is {}, eos token id is {}'.format(self.eos_token, self.eos_token_id))\n",
    "        self.model = GPT2LMHeadModel.from_pretrained(model_name)\n",
    "        self.vocab_size = len(self.tokenizer)\n",
    "        print ('Resizing model embedding...')\n",
    "        self.model.resize_token_embeddings(len(self.tokenizer)) \n",
    "        print ('Model embedding resized!')\n",
    "        self.embed_dim = self.model.config.hidden_size\n",
    "\n",
    "    def add_special_token(self, special_token):\n",
    "        if special_token in self.tokenizer.vocab:\n",
    "            print (special_token + ' token exists.')\n",
    "        else:\n",
    "            print ('Add token to the tokenizer.')\n",
    "            print ('Original vocabulary size is {}'.format(len(self.tokenizer)))\n",
    "            self.tokenizer.add_tokens([special_token])\n",
    "            print ('Vocabulary size after extension is {}'.format(len(self.tokenizer)))\n",
    "            assert len(self.tokenizer.convert_tokens_to_ids([special_token])) == 1\n",
    "        special_token_id = self.tokenizer.convert_tokens_to_ids([special_token])[0]\n",
    "        return special_token, special_token_id\n",
    "\n",
    "    def compute_logits_and_hidden_states(self, input_ids):\n",
    "        # used for advanced decoding\n",
    "        # input_ids: 1 x seqlen\n",
    "        outputs = self.model(input_ids=input_ids, output_hidden_states=True)\n",
    "        last_hidden_states = outputs.hidden_states[-1]\n",
    "        logits = outputs.logits\n",
    "        return last_hidden_states, logits\n",
    "\n",
    "    def forward(self, input_ids, labels, margin):\n",
    "        bsz, seqlen = input_ids.size()\n",
    "        outputs = self.model(input_ids=input_ids, output_hidden_states=True)\n",
    "        logits = outputs.logits\n",
    "        assert logits.size() == torch.Size([bsz, seqlen, self.vocab_size])\n",
    "        last_hidden_states = outputs.hidden_states[-1]\n",
    "        assert last_hidden_states.size() == torch.Size([bsz, seqlen, self.embed_dim])\n",
    "        mle_loss = train_fct(logits.view(-1, self.vocab_size), labels.view(-1))\n",
    "\n",
    "        norm_rep = last_hidden_states / last_hidden_states.norm(dim=2, keepdim=True)\n",
    "        cosine_scores = torch.matmul(norm_rep, norm_rep.transpose(1,2)) \n",
    "        assert cosine_scores.size() == torch.Size([bsz, seqlen, seqlen])\n",
    "        cl_loss = contrastive_loss(margin, cosine_scores, input_ids, self.pad_token_id, prefix_len=0)\n",
    "        return mle_loss, cl_loss\n",
    "\n",
    "    def eval_loss(self, input_ids, labels):\n",
    "        bsz, seqlen = input_ids.size()\n",
    "        outputs = self.model(input_ids=input_ids, output_hidden_states=True)\n",
    "        logits = outputs.logits\n",
    "        assert logits.size() == torch.Size([bsz, seqlen, self.vocab_size])\n",
    "        last_hidden_states = outputs.hidden_states[-1]\n",
    "        assert last_hidden_states.size() == torch.Size([bsz, seqlen, self.embed_dim])\n",
    "        mle_loss = val_fct(logits.view(-1, self.vocab_size), labels.view(-1))\n",
    "        assert mle_loss.size() == torch.Size([bsz * seqlen])\n",
    "        mask_tmp = labels.masked_fill(~labels.eq(-100), 1.0)\n",
    "        mask = mask_tmp.masked_fill(mask_tmp.eq(-100), 0.0)\n",
    "        # sum \n",
    "        mle_loss_sum = torch.sum(mle_loss)\n",
    "        token_num_sum = torch.sum(mask)\n",
    "        return mle_loss_sum, token_num_sum\n",
    "\n",
    "    def save_model(self, ckpt_save_path):\n",
    "        import os\n",
    "        if os.path.exists(ckpt_save_path):\n",
    "            pass\n",
    "        else: # recursively construct directory\n",
    "            os.makedirs(ckpt_save_path, exist_ok=True)\n",
    "        # save model\n",
    "        self.model.save_pretrained(ckpt_save_path)\n",
    "        # save tokenizer\n",
    "        self.tokenizer.save_pretrained(ckpt_save_path)\n",
    "\n",
    "    def parse_sentences(self, text, num_of_sentences_to_keep):\n",
    "        item_list = text.split('.')\n",
    "        res_list = item_list[:num_of_sentences_to_keep]\n",
    "        if len(item_list) > num_of_sentences_to_keep:\n",
    "            res_text = '.'.join(res_list).strip('.') + '.'\n",
    "        else:\n",
    "            res_text = '.'.join(res_list).strip('.').strip()\n",
    "        return res_text\n",
    "\n",
    "    def parse_generated_result(self, output, num_of_sentences_to_keep):\n",
    "        output_text = self.tokenizer.decode(output)\n",
    "        item_list = output_text.split(self.eos_token)\n",
    "        full_text = self.eos_token.join(item_list[:2]).strip()\n",
    "        full_text = self.parse_sentences(full_text, num_of_sentences_to_keep)\n",
    "        generated_text = item_list[1].strip()\n",
    "        generated_text = self.parse_sentences(generated_text, num_of_sentences_to_keep)\n",
    "        return full_text, generated_text\n",
    "\n",
    "    # decoding functions\n",
    "    # ------------------------------------------------------- #\n",
    "\n",
    "    def parse_output_token_list(self, output):\n",
    "        output = output.tolist()\n",
    "        res_list = []\n",
    "        for token_id in output:\n",
    "            if token_id == self.sos_token_id:\n",
    "                continue\n",
    "            elif token_id == self.eos_token_id:\n",
    "                break\n",
    "            else:\n",
    "                res_list.append(token_id)\n",
    "        text = self.tokenizer.decode(res_list).strip()\n",
    "        return ' '.join(text.split()).strip()\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def magic_search(self, input_ids, beam_width, alpha, decoding_len, beta, image_instance, clip, \n",
    "        clip_text_max_len):#, add_token_level_score=False):\n",
    "        prefix_len = input_ids.size()[1]\n",
    "        from utlis import PlugAndPlayContrastiveDecodingOneStepFast\n",
    "        past_key_values, last_hidden_states, logits = None, None, None\n",
    "        generated = [item for item in input_ids.tolist()]\n",
    "        input_ids_for_class = input_ids.clone()\n",
    "\n",
    "        image_embeds = clip.compute_image_representation_from_image_instance(image_instance)\n",
    "\n",
    "        start_time = datetime.datetime.now()\n",
    "\n",
    "        # the maximum supported length of generation for SimCTG is 256\n",
    "        # to support longer generated length, you can re-train the SimCTG model with longer sequences\n",
    "        decoding_len = decoding_len - prefix_len\n",
    "        for step in range(decoding_len):\n",
    "            input_ids, past_key_values, last_hidden_states, logits, input_ids_for_class = \\\n",
    "            PlugAndPlayContrastiveDecodingOneStepFast(\n",
    "                self.model, \n",
    "                input_ids, \n",
    "                prefix_len,\n",
    "                beam_width, \n",
    "                alpha, \n",
    "                beta, \n",
    "                self.tokenizer,\n",
    "                image_embeds, \n",
    "                clip, \n",
    "                clip_text_max_len,\n",
    "                past_key_values,\n",
    "                last_hidden_states,\n",
    "                logits,\n",
    "                first_step=step==0,\n",
    "                input_ids_for_class=input_ids_for_class,\n",
    "            )\n",
    "        end_time = datetime.datetime.now()\n",
    "        time_diff = (end_time - start_time)\n",
    "        execution_time = time_diff.total_seconds() * 1000\n",
    "        return self.parse_output_token_list(input_ids_for_class[0])\n",
    "\n",
    "    def fast_contrastive_search(self, input_ids, beam_width, alpha, decoding_len):\n",
    "        '''\n",
    "           input_ids: prefix input; 1 x prefix_len\n",
    "           decoding_len: how many tokens to generate\n",
    "           beam_width: size of candidate pool during decoding\n",
    "           alpha: regulates importance of model confidence and degeneration penalty\n",
    "        '''\n",
    "        self.model.eval()\n",
    "        from utlis import ContrastiveDecodingOneStepFast\n",
    "        # sanity check\n",
    "        assert alpha >= 0. and alpha <= 1.0\n",
    "        \n",
    "        # fast mode\n",
    "        prefix_len = input_ids.size()[1]\n",
    "        batch_size, seqlen = input_ids.size()\n",
    "        #generated = [[] for _ in range(batch_size)]\n",
    "        generated = [item for item in input_ids.tolist()]\n",
    "        past_key_values = None\n",
    "        last_hidden_states = None\n",
    "        logits = None\n",
    "        decoding_len = decoding_len - prefix_len\n",
    "        for step in range(decoding_len):\n",
    "            input_ids, past_key_values, last_hidden_states, logits = ContrastiveDecodingOneStepFast(\n",
    "                self.model,\n",
    "                input_ids,\n",
    "                beam_width,\n",
    "                alpha,\n",
    "                past_key_values,\n",
    "                last_hidden_states,\n",
    "                self.tokenizer,\n",
    "                logits,\n",
    "                first_step=step == 0,\n",
    "            )\n",
    "            tokens = input_ids.squeeze(dim=-1).tolist()\n",
    "            for idx, t in enumerate(tokens):\n",
    "                generated[idx].append(t)\n",
    "        return self.parse_output_token_list(torch.LongTensor(generated[0]))\n",
    "\n",
    "    def top_k_sampling(self, input_ids, k, decoding_len):\n",
    "        _, prefix_len = input_ids.size()\n",
    "        output = self.model.generate(\n",
    "                            input_ids, \n",
    "                            do_sample=True, \n",
    "                            max_length=decoding_len, \n",
    "                            top_p=1.0,\n",
    "                            top_k=k)\n",
    "        return self.parse_output_token_list(output[0])\n",
    "\n",
    "    def nucleus_sampling(self, input_ids, nucleus_p, decoding_len):\n",
    "        _, prefix_len = input_ids.size()\n",
    "        output = self.model.generate(\n",
    "                            input_ids, \n",
    "                            do_sample=True, \n",
    "                            max_length=decoding_len, \n",
    "                            top_p=nucleus_p,\n",
    "                            top_k=0)\n",
    "        return self.parse_output_token_list(output[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7cf582bf",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-08T15:07:30.223321Z",
     "iopub.status.busy": "2023-03-08T15:07:30.222634Z",
     "iopub.status.idle": "2023-03-08T16:56:56.418026Z",
     "shell.execute_reply": "2023-03-08T16:56:56.416621Z"
    },
    "papermill": {
     "duration": 6566.20235,
     "end_time": "2023-03-08T16:56:56.420418",
     "exception": false,
     "start_time": "2023-03-08T15:07:30.218068",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cuda is available.\n",
      "Using single GPU training.\n",
      "Add eos token to data!\n",
      "Loading data...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d235cdf150fb49f89511c38fac46c418",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading ()olve/main/vocab.json:   0%|          | 0.00/1.04M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0bdd1e4469834d609780bedc4ed49e42",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading ()olve/main/merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fc78beccf37c4895a939deb837bd5e37",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading ()/main/tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "01f09e97dc014aed876b048785bd1879",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading ()lve/main/config.json:   0%|          | 0.00/665 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Add token to the tokenizer.\n",
      "Original vocabulary size is 50257\n",
      "Vocabulary size after extension is 50258\n",
      "sos token is <-start_of_text->, sos token id is 50257\n",
      "Add token to the tokenizer.\n",
      "Original vocabulary size is 50258\n",
      "Vocabulary size after extension is 50259\n",
      "pad token is <-pad->, pad token id is 50258\n",
      "eos token is <|endoftext|>, eos token id is 50256\n",
      "Processing /kaggle/input/flickr30k/flickr30k/flickr30k/flickr30k_train.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "| |       #                                      | 144999 Elapsed Time: 0:00:17\n",
      "- | #                                               | 882 Elapsed Time: 0:00:00"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/flickr30k/flickr30k/flickr30k/flickr30k_train.json processed!\n",
      "Processing /kaggle/input/flickr30k/flickr30k/flickr30k/flickr30k_val.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "| |     #                                          | 5069 Elapsed Time: 0:00:00\n",
      "- | #                                               | 878 Elapsed Time: 0:00:00"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/flickr30k/flickr30k/flickr30k/flickr30k_val.json processed!\n",
      "Processing /kaggle/input/flickr30k/flickr30k/flickr30k/flickr30k_test.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "| |     #                                          | 4999 Elapsed Time: 0:00:00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/flickr30k/flickr30k/flickr30k/flickr30k_test.json processed!\n",
      "train number:145000, dev number:5070, test number:5000\n",
      "Data loaded.\n",
      "############################################################\n",
      "Start Training...\n",
      "Initializaing SimCTG model...\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Add token to the tokenizer.\n",
      "Original vocabulary size is 50257\n",
      "Vocabulary size after extension is 50258\n",
      "sos token is <-start_of_text->, sos token id is 50257\n",
      "Add token to the tokenizer.\n",
      "Original vocabulary size is 50258\n",
      "Vocabulary size after extension is 50259\n",
      "pad token is <-pad->, pad token id is 50258\n",
      "eos token is <|endoftext|>, eos token id is 50256\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "59ab18fb441b4a4ea98f211aa693b9e6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading ()\"pytorch_model.bin\";:   0%|          | 0.00/548M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aa5893b927154e1b9e730e26538c11c1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading ()neration_config.json:   0%|          | 0.00/124 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resizing model embedding...\n",
      "Model embedding resized!\n",
      "Model loaded\n",
      "total training steps is 10000, warmup steps is 1000\n",
      "--------------------------------------------------------------------------\n",
      "Start Training:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/transformers/optimization.py:310: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  FutureWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At training steps 50, training MLE loss is 83.92462783813477, train CL loss is 0.44443097040057183\n",
      "At training steps 100, training MLE loss is 72.84322461128235, train CL loss is 0.4362902021408081\n",
      "At training steps 150, training MLE loss is 53.687166572411854, train CL loss is 0.34938953834275405\n",
      "At training steps 200, training MLE loss is 41.61146593719721, train CL loss is 0.3153571259789169\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "- | #                                                 | 2 Elapsed Time: 0:00:00"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At training steps 250, training MLE loss is 34.08618326663971, train CL loss is 0.29354951579868793\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "| |                   #                             | 156 Elapsed Time: 0:00:07\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At training steps 250, training MLE loss is 34.08618326663971, train CL loss is 0.29354951579868793, validation loss is 3.5151402564134524\n",
      "Saving model...\n",
      "Model Saved!\n",
      "-----------------------------------\n",
      "At training steps 300, training MLE loss is 3.592324674129486, train CL loss is 0.18780366599559783\n",
      "At training steps 350, training MLE loss is 3.513131790161133, train CL loss is 0.17365160498768092\n",
      "At training steps 400, training MLE loss is 3.450180763800939, train CL loss is 0.1557591376826167\n",
      "At training steps 450, training MLE loss is 3.408612800836563, train CL loss is 0.1397604699851945\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "- | #                                                 | 2 Elapsed Time: 0:00:00"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At training steps 500, training MLE loss is 3.371379598617554, train CL loss is 0.12458348222076893\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "| |                   #                             | 156 Elapsed Time: 0:00:07\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At training steps 500, training MLE loss is 3.371379598617554, train CL loss is 0.12458348222076893, validation loss is 3.054257986131999\n",
      "Saving model...\n",
      "Model Saved!\n",
      "-----------------------------------\n",
      "At training steps 550, training MLE loss is 3.184923678636551, train CL loss is 0.04803856929764152\n",
      "At training steps 600, training MLE loss is 3.16038372695446, train CL loss is 0.0438922195835039\n",
      "At training steps 650, training MLE loss is 3.139466874996821, train CL loss is 0.041009602152432004\n",
      "At training steps 700, training MLE loss is 3.123450574874878, train CL loss is 0.03889434695942327\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "- | #                                                 | 2 Elapsed Time: 0:00:00"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At training steps 750, training MLE loss is 3.113983025312424, train CL loss is 0.03705008470267057\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "| |                   #                             | 156 Elapsed Time: 0:00:07\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At training steps 750, training MLE loss is 3.113983025312424, train CL loss is 0.03705008470267057, validation loss is 2.9177996358453493\n",
      "Saving model...\n",
      "Model Saved!\n",
      "-----------------------------------\n",
      "At training steps 800, training MLE loss is 3.042651650905609, train CL loss is 0.027111453879624606\n",
      "At training steps 850, training MLE loss is 3.035914190411568, train CL loss is 0.026514992411248387\n",
      "At training steps 900, training MLE loss is 3.031106897989909, train CL loss is 0.0258994620355467\n",
      "At training steps 950, training MLE loss is 3.02278921186924, train CL loss is 0.02517482613446191\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "- | #                                                 | 2 Elapsed Time: 0:00:00"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At training steps 1000, training MLE loss is 3.0111970188617705, train CL loss is 0.02448700226470828\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "| |                  #                              | 156 Elapsed Time: 0:00:07\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At training steps 1000, training MLE loss is 3.0111970188617705, train CL loss is 0.02448700226470828, validation loss is 2.857609181242913\n",
      "Saving model...\n",
      "Model Saved!\n",
      "-----------------------------------\n",
      "At training steps 1050, training MLE loss is 2.9674647784233095, train CL loss is 0.020417435094714165\n",
      "At training steps 1100, training MLE loss is 2.9685023760795595, train CL loss is 0.020571842447388917\n",
      "At training steps 1150, training MLE loss is 2.95710551738739, train CL loss is 0.02023087680339813\n",
      "At training steps 1200, training MLE loss is 2.952403658926487, train CL loss is 0.019910916064400225\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "- | #                                                 | 2 Elapsed Time: 0:00:00"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At training steps 1250, training MLE loss is 2.9460953993797303, train CL loss is 0.019506474005058408\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "| |                   #                             | 156 Elapsed Time: 0:00:07\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At training steps 1250, training MLE loss is 2.9460953993797303, train CL loss is 0.019506474005058408, validation loss is 2.8262295286135233\n",
      "Saving model...\n",
      "Model Saved!\n",
      "-----------------------------------\n",
      "At training steps 1300, training MLE loss is 2.900182839632034, train CL loss is 0.017074375608935953\n",
      "At training steps 1350, training MLE loss is 2.9033000218868255, train CL loss is 0.017205944922752677\n",
      "At training steps 1400, training MLE loss is 2.901982849438985, train CL loss is 0.01702415685945501\n",
      "At training steps 1450, training MLE loss is 2.900348283946514, train CL loss is 0.016782414014451207\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "- | #                                                 | 2 Elapsed Time: 0:00:00"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At training steps 1500, training MLE loss is 2.892314726829529, train CL loss is 0.016625919630751013\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "| |                   #                             | 156 Elapsed Time: 0:00:07\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At training steps 1500, training MLE loss is 2.892314726829529, train CL loss is 0.016625919630751013, validation loss is 2.8019682970374427\n",
      "Saving model...\n",
      "Model Saved!\n",
      "-----------------------------------\n",
      "At training steps 1550, training MLE loss is 2.8704008090496065, train CL loss is 0.01529899430461228\n",
      "At training steps 1600, training MLE loss is 2.8702472406625748, train CL loss is 0.01513201936846599\n",
      "At training steps 1650, training MLE loss is 2.8681112058957416, train CL loss is 0.015091005633585154\n",
      "At training steps 1700, training MLE loss is 2.8651502364873886, train CL loss is 0.014923128851223736\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "- | #                                                 | 2 Elapsed Time: 0:00:00"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At training steps 1750, training MLE loss is 2.8614171261787416, train CL loss is 0.014708523183129728\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "| |                   #                             | 156 Elapsed Time: 0:00:07\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At training steps 1750, training MLE loss is 2.8614171261787416, train CL loss is 0.014708523183129728, validation loss is 2.7791054178771764\n",
      "Saving model...\n",
      "Model Saved!\n",
      "-----------------------------------\n",
      "At training steps 1800, training MLE loss is 2.8388427472114564, train CL loss is 0.013510034438222646\n",
      "At training steps 1850, training MLE loss is 2.8390036702156065, train CL loss is 0.013490996335167437\n",
      "At training steps 1900, training MLE loss is 2.8416985273361206, train CL loss is 0.01341573273918281\n",
      "At training steps 1950, training MLE loss is 2.8401260021328927, train CL loss is 0.013257704223506153\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "- | #                                                 | 2 Elapsed Time: 0:00:00"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At training steps 2000, training MLE loss is 2.8384567608833313, train CL loss is 0.013172543717548252\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "| |                   #                             | 156 Elapsed Time: 0:00:07\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At training steps 2000, training MLE loss is 2.8384567608833313, train CL loss is 0.013172543717548252, validation loss is 2.766005718898537\n",
      "Saving model...\n",
      "Model Saved!\n",
      "-----------------------------------\n",
      "At training steps 2050, training MLE loss is 2.827410578727722, train CL loss is 0.012883469117805363\n",
      "At training steps 2100, training MLE loss is 2.8272238582372666, train CL loss is 0.012678578358609228\n",
      "At training steps 2150, training MLE loss is 2.827666489283244, train CL loss is 0.01256366740136097\n",
      "At training steps 2200, training MLE loss is 2.82239592730999, train CL loss is 0.012377224022056908\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "- | #                                                 | 2 Elapsed Time: 0:00:00"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At training steps 2250, training MLE loss is 2.8192341213226317, train CL loss is 0.012233124196529388\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "| |                   #                             | 156 Elapsed Time: 0:00:07\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At training steps 2250, training MLE loss is 2.8192341213226317, train CL loss is 0.012233124196529388, validation loss is 2.7555367635917354\n",
      "Saving model...\n",
      "Model Saved!\n",
      "-----------------------------------\n",
      "At training steps 2300, training MLE loss is 2.81224271774292, train CL loss is 0.011769840074703098\n",
      "At training steps 2350, training MLE loss is 2.8072637128829956, train CL loss is 0.011619221034925431\n",
      "At training steps 2400, training MLE loss is 2.802893200715383, train CL loss is 0.011492114181940754\n",
      "At training steps 2450, training MLE loss is 2.8034437239170074, train CL loss is 0.011441936650080607\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "- | #                                                 | 2 Elapsed Time: 0:00:00"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At training steps 2500, training MLE loss is 2.800370178222656, train CL loss is 0.011356949927285314\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "| |                  #                              | 156 Elapsed Time: 0:00:07\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At training steps 2500, training MLE loss is 2.800370178222656, train CL loss is 0.011356949927285314, validation loss is 2.747666124716369\n",
      "Saving model...\n",
      "Model Saved!\n",
      "-----------------------------------\n",
      "At training steps 2550, training MLE loss is 2.795918744802475, train CL loss is 0.01083222493994981\n",
      "At training steps 2600, training MLE loss is 2.7981826668977736, train CL loss is 0.010667047089664266\n",
      "At training steps 2650, training MLE loss is 2.792562716801961, train CL loss is 0.01065063317772001\n",
      "At training steps 2700, training MLE loss is 2.791425256729126, train CL loss is 0.010574893637094646\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "- | #                                                 | 2 Elapsed Time: 0:00:00"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At training steps 2750, training MLE loss is 2.793423658847809, train CL loss is 0.010532991450745613\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "| |                  #                              | 156 Elapsed Time: 0:00:07\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At training steps 2750, training MLE loss is 2.793423658847809, train CL loss is 0.010532991450745613, validation loss is 2.737674119031025\n",
      "Saving model...\n",
      "Model Saved!\n",
      "-----------------------------------\n",
      "At training steps 2800, training MLE loss is 2.787177857160568, train CL loss is 0.010515369405038655\n",
      "At training steps 2850, training MLE loss is 2.78814116358757, train CL loss is 0.010501355009619146\n",
      "At training steps 2900, training MLE loss is 2.785188220739365, train CL loss is 0.010438585987625022\n",
      "At training steps 2950, training MLE loss is 2.7830337527394295, train CL loss is 0.010362968878471292\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "- | #                                                 | 2 Elapsed Time: 0:00:00"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At training steps 3000, training MLE loss is 2.781862416982651, train CL loss is 0.010309814175590872\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "| |                   #                             | 156 Elapsed Time: 0:00:07\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At training steps 3000, training MLE loss is 2.781862416982651, train CL loss is 0.010309814175590872, validation loss is 2.7335590921646116\n",
      "Saving model...\n",
      "Model Saved!\n",
      "-----------------------------------\n",
      "At training steps 3050, training MLE loss is 2.76361465215683, train CL loss is 0.00997621861519292\n",
      "At training steps 3100, training MLE loss is 2.7660193622112272, train CL loss is 0.0098508949985262\n",
      "At training steps 3150, training MLE loss is 2.76974781870842, train CL loss is 0.009873347042594105\n",
      "At training steps 3200, training MLE loss is 2.7673635298013686, train CL loss is 0.0098778194678016\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "- | #                                                 | 2 Elapsed Time: 0:00:00"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At training steps 3250, training MLE loss is 2.763581642150879, train CL loss is 0.00981132491491735\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "| |                   #                             | 156 Elapsed Time: 0:00:07\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At training steps 3250, training MLE loss is 2.763581642150879, train CL loss is 0.00981132491491735, validation loss is 2.7277971083312766\n",
      "Saving model...\n",
      "Model Saved!\n",
      "-----------------------------------\n",
      "At training steps 3300, training MLE loss is 2.7584842908382416, train CL loss is 0.009503593598492444\n",
      "At training steps 3350, training MLE loss is 2.7620927190780638, train CL loss is 0.00947822299436666\n",
      "At training steps 3400, training MLE loss is 2.764630165497462, train CL loss is 0.009452839442528784\n",
      "At training steps 3450, training MLE loss is 2.769488011598587, train CL loss is 0.009476210117572919\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "- | #                                                 | 2 Elapsed Time: 0:00:00"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At training steps 3500, training MLE loss is 2.765860366344452, train CL loss is 0.009443317642435431\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "| |                   #                             | 156 Elapsed Time: 0:00:07\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At training steps 3500, training MLE loss is 2.765860366344452, train CL loss is 0.009443317642435431, validation loss is 2.7236622967842505\n",
      "Saving model...\n",
      "Model Saved!\n",
      "-----------------------------------\n",
      "At training steps 3550, training MLE loss is 2.738622440099716, train CL loss is 0.009364554595667868\n",
      "At training steps 3600, training MLE loss is 2.7500449538230898, train CL loss is 0.009269248078344389\n",
      "At training steps 3650, training MLE loss is 2.7481330275535583, train CL loss is 0.009234349229373037\n",
      "At training steps 3700, training MLE loss is 2.747271551191807, train CL loss is 0.009202250353991985\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "- | #                                                 | 2 Elapsed Time: 0:00:00"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At training steps 3750, training MLE loss is 2.7494402050971987, train CL loss is 0.009178293886128813\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "| |                   #                             | 156 Elapsed Time: 0:00:07\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At training steps 3750, training MLE loss is 2.7494402050971987, train CL loss is 0.009178293886128813, validation loss is 2.7173725790278604\n",
      "Saving model...\n",
      "Model Saved!\n",
      "-----------------------------------\n",
      "At training steps 3800, training MLE loss is 2.7407121777534487, train CL loss is 0.008862356750760227\n",
      "At training steps 3850, training MLE loss is 2.744905315041542, train CL loss is 0.008815132634481415\n",
      "At training steps 3900, training MLE loss is 2.7435131537914277, train CL loss is 0.008903665233713885\n",
      "At training steps 3950, training MLE loss is 2.7441676545143125, train CL loss is 0.00889221417834051\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "- | #                                                 | 2 Elapsed Time: 0:00:00"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At training steps 4000, training MLE loss is 2.745231878042221, train CL loss is 0.00885818592319265\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "| |                  #                              | 156 Elapsed Time: 0:00:07\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At training steps 4000, training MLE loss is 2.745231878042221, train CL loss is 0.00885818592319265, validation loss is 2.7148893380566217\n",
      "Saving model...\n",
      "Model Saved!\n",
      "-----------------------------------\n",
      "At training steps 4050, training MLE loss is 2.742732762098312, train CL loss is 0.008839131998829543\n",
      "At training steps 4100, training MLE loss is 2.735285061597824, train CL loss is 0.008749975003302097\n",
      "At training steps 4150, training MLE loss is 2.73658722837766, train CL loss is 0.00869693385825182\n",
      "At training steps 4200, training MLE loss is 2.734177041053772, train CL loss is 0.008616921213106253\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "- | #                                                 | 2 Elapsed Time: 0:00:00"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At training steps 4250, training MLE loss is 2.735126318693161, train CL loss is 0.00856752954935655\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "| |                   #                             | 156 Elapsed Time: 0:00:07\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At training steps 4250, training MLE loss is 2.735126318693161, train CL loss is 0.00856752954935655, validation loss is 2.7102826596639256\n",
      "Saving model...\n",
      "Model Saved!\n",
      "-----------------------------------\n",
      "At training steps 4300, training MLE loss is 2.7232016348838806, train CL loss is 0.008527179346419871\n",
      "At training steps 4350, training MLE loss is 2.7384156328439713, train CL loss is 0.008484955043531955\n",
      "At training steps 4400, training MLE loss is 2.7344014767805733, train CL loss is 0.008439646496747931\n",
      "At training steps 4450, training MLE loss is 2.7294409558176995, train CL loss is 0.008369186226045712\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "- | #                                                 | 1 Elapsed Time: 0:00:00"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At training steps 4500, training MLE loss is 2.7303160026073456, train CL loss is 0.008359922855626792\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "| |                  #                              | 156 Elapsed Time: 0:00:07\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At training steps 4500, training MLE loss is 2.7303160026073456, train CL loss is 0.008359922855626792, validation loss is 2.70566608852855\n",
      "Saving model...\n",
      "Model Saved!\n",
      "-----------------------------------\n",
      "At training steps 4550, training MLE loss is 2.730186598300934, train CL loss is 0.008355398597195744\n",
      "At training steps 4600, training MLE loss is 2.7265275639295576, train CL loss is 0.008326253674458712\n",
      "At training steps 4650, training MLE loss is 2.724432614247004, train CL loss is 0.00822322440566495\n",
      "At training steps 4700, training MLE loss is 2.7197642180323602, train CL loss is 0.008157024655956776\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "- | #                                                 | 2 Elapsed Time: 0:00:00"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At training steps 4750, training MLE loss is 2.7201459259986875, train CL loss is 0.008148226924240588\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "| |                   #                             | 156 Elapsed Time: 0:00:07\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At training steps 4750, training MLE loss is 2.7201459259986875, train CL loss is 0.008148226924240588, validation loss is 2.7030218033956315\n",
      "Saving model...\n",
      "Model Saved!\n",
      "-----------------------------------\n",
      "At training steps 4800, training MLE loss is 2.716551969051361, train CL loss is 0.007949690273962915\n",
      "At training steps 4850, training MLE loss is 2.7174752163887024, train CL loss is 0.007993523911572993\n",
      "At training steps 4900, training MLE loss is 2.715788841644923, train CL loss is 0.008005436526921888\n",
      "At training steps 4950, training MLE loss is 2.716864178776741, train CL loss is 0.007994086053222417\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "- | #                                                 | 2 Elapsed Time: 0:00:00"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At training steps 5000, training MLE loss is 2.7152415375709533, train CL loss is 0.007951709297019988\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "| |                   #                             | 156 Elapsed Time: 0:00:07\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At training steps 5000, training MLE loss is 2.7152415375709533, train CL loss is 0.007951709297019988, validation loss is 2.69948491169477\n",
      "Saving model...\n",
      "Model Saved!\n",
      "-----------------------------------\n",
      "At training steps 5050, training MLE loss is 2.715855984687805, train CL loss is 0.007893372485414147\n",
      "At training steps 5100, training MLE loss is 2.715512656569481, train CL loss is 0.007827768211718648\n",
      "At training steps 5150, training MLE loss is 2.7127215405305227, train CL loss is 0.0077963351652336615\n",
      "At training steps 5200, training MLE loss is 2.7103149506449697, train CL loss is 0.007753568839980289\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "- | #                                                 | 2 Elapsed Time: 0:00:00"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At training steps 5250, training MLE loss is 2.7122237892150878, train CL loss is 0.007727227103896439\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "| |                   #                             | 156 Elapsed Time: 0:00:07\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At training steps 5250, training MLE loss is 2.7122237892150878, train CL loss is 0.007727227103896439, validation loss is 2.6970879419098535\n",
      "Saving model...\n",
      "Model Saved!\n",
      "-----------------------------------\n",
      "At training steps 5300, training MLE loss is 2.708297129869461, train CL loss is 0.0076117058959789576\n",
      "At training steps 5350, training MLE loss is 2.6995433455705644, train CL loss is 0.007644788202596829\n",
      "At training steps 5400, training MLE loss is 2.699229146639506, train CL loss is 0.007619513922836631\n",
      "At training steps 5450, training MLE loss is 2.695963822901249, train CL loss is 0.0075550370698329065\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "- | #                                                 | 2 Elapsed Time: 0:00:00"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At training steps 5500, training MLE loss is 2.6976191775798797, train CL loss is 0.007527238368522376\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "| |                  #                              | 156 Elapsed Time: 0:00:07\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At training steps 5500, training MLE loss is 2.6976191775798797, train CL loss is 0.007527238368522376, validation loss is 2.6941646569690954\n",
      "Saving model...\n",
      "Model Saved!\n",
      "-----------------------------------\n",
      "At training steps 5550, training MLE loss is 2.7106817746162415, train CL loss is 0.007523693835828453\n",
      "At training steps 5600, training MLE loss is 2.711736099123955, train CL loss is 0.00761734014027752\n",
      "At training steps 5650, training MLE loss is 2.7101295936107634, train CL loss is 0.007561608258790026\n",
      "At training steps 5700, training MLE loss is 2.708779515326023, train CL loss is 0.007563677813159302\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "- | #                                                 | 2 Elapsed Time: 0:00:00"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At training steps 5750, training MLE loss is 2.7100850930213927, train CL loss is 0.007557152172550559\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "| |                   #                             | 156 Elapsed Time: 0:00:07\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At training steps 5750, training MLE loss is 2.7100850930213927, train CL loss is 0.007557152172550559, validation loss is 2.692822618264701\n",
      "Saving model...\n",
      "Model Saved!\n",
      "-----------------------------------\n",
      "At training steps 5800, training MLE loss is 2.7016984832286837, train CL loss is 0.0073121576523408295\n",
      "At training steps 5850, training MLE loss is 2.6935718947649003, train CL loss is 0.007454829892376438\n",
      "At training steps 5900, training MLE loss is 2.6981422503789267, train CL loss is 0.007408060695355137\n",
      "At training steps 5950, training MLE loss is 2.691614710688591, train CL loss is 0.0074066453881096094\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "- | #                                                 | 2 Elapsed Time: 0:00:00"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At training steps 6000, training MLE loss is 2.6914072597026824, train CL loss is 0.0073820413085632025\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "| |                   #                             | 156 Elapsed Time: 0:00:07\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At training steps 6000, training MLE loss is 2.6914072597026824, train CL loss is 0.0073820413085632025, validation loss is 2.6895911284787175\n",
      "Saving model...\n",
      "Model Saved!\n",
      "-----------------------------------\n",
      "At training steps 6050, training MLE loss is 2.7059673738479613, train CL loss is 0.007228508542757481\n",
      "At training steps 6100, training MLE loss is 2.7020372474193572, train CL loss is 0.007241977404337376\n",
      "At training steps 6150, training MLE loss is 2.6970879077911376, train CL loss is 0.007254367634498824\n",
      "At training steps 6200, training MLE loss is 2.696754969358444, train CL loss is 0.007246535188169218\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "- | #                                                 | 2 Elapsed Time: 0:00:00"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At training steps 6250, training MLE loss is 2.694045554637909, train CL loss is 0.007220228898338974\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "| |                   #                             | 156 Elapsed Time: 0:00:07\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At training steps 6250, training MLE loss is 2.694045554637909, train CL loss is 0.007220228898338974, validation loss is 2.6883660596066226\n",
      "Saving model...\n",
      "Model Saved!\n",
      "-----------------------------------\n",
      "At training steps 6300, training MLE loss is 2.6984809505939484, train CL loss is 0.007306446109432727\n",
      "At training steps 6350, training MLE loss is 2.6923750042915344, train CL loss is 0.007230684086680412\n",
      "At training steps 6400, training MLE loss is 2.6910815262794494, train CL loss is 0.007168489331379532\n",
      "At training steps 6450, training MLE loss is 2.691974640786648, train CL loss is 0.007152304312912747\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "- | #                                                 | 2 Elapsed Time: 0:00:00"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At training steps 6500, training MLE loss is 2.693642969608307, train CL loss is 0.007137359621934593\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "| |                   #                             | 156 Elapsed Time: 0:00:07\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At training steps 6500, training MLE loss is 2.693642969608307, train CL loss is 0.007137359621934593, validation loss is 2.6874240158819007\n",
      "Saving model...\n",
      "Model Saved!\n",
      "-----------------------------------\n",
      "At training steps 6550, training MLE loss is 2.6743551540374755, train CL loss is 0.007008451763540507\n",
      "At training steps 6600, training MLE loss is 2.674326540231705, train CL loss is 0.007008435275638476\n",
      "At training steps 6650, training MLE loss is 2.679766837358475, train CL loss is 0.007061101321596652\n",
      "At training steps 6700, training MLE loss is 2.6806391644477845, train CL loss is 0.007070142364827916\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "- | #                                                 | 2 Elapsed Time: 0:00:00"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At training steps 6750, training MLE loss is 2.6804315302371977, train CL loss is 0.0070734163932502266\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "| |                   #                             | 156 Elapsed Time: 0:00:07\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At training steps 6750, training MLE loss is 2.6804315302371977, train CL loss is 0.0070734163932502266, validation loss is 2.6857722811379277\n",
      "Saving model...\n",
      "Model Saved!\n",
      "-----------------------------------\n",
      "At training steps 6800, training MLE loss is 2.6853172075748444, train CL loss is 0.007078693034127354\n",
      "At training steps 6850, training MLE loss is 2.6871281909942626, train CL loss is 0.0071321763738524165\n",
      "At training steps 6900, training MLE loss is 2.6831399778525036, train CL loss is 0.007091397137070695\n",
      "At training steps 6950, training MLE loss is 2.6779790437221527, train CL loss is 0.00704733079590369\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "- | #                                                 | 2 Elapsed Time: 0:00:00"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At training steps 7000, training MLE loss is 2.6811902334690094, train CL loss is 0.007029988791327923\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "| |                  #                              | 156 Elapsed Time: 0:00:07\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At training steps 7000, training MLE loss is 2.6811902334690094, train CL loss is 0.007029988791327923, validation loss is 2.6833862317563435\n",
      "Saving model...\n",
      "Model Saved!\n",
      "-----------------------------------\n",
      "At training steps 7050, training MLE loss is 2.6911846101284027, train CL loss is 0.007057116564828903\n",
      "At training steps 7100, training MLE loss is 2.6858304315805435, train CL loss is 0.007008454032475128\n",
      "At training steps 7150, training MLE loss is 2.6837958268324535, train CL loss is 0.0070199937404443824\n",
      "At training steps 7200, training MLE loss is 2.6797623592615127, train CL loss is 0.007006671588751488\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "- | #                                                 | 2 Elapsed Time: 0:00:00"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At training steps 7250, training MLE loss is 2.6795938377380373, train CL loss is 0.006984746418427676\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "| |                  #                              | 156 Elapsed Time: 0:00:07\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At training steps 7250, training MLE loss is 2.6795938377380373, train CL loss is 0.006984746418427676, validation loss is 2.681625820892432\n",
      "Saving model...\n",
      "Model Saved!\n",
      "-----------------------------------\n",
      "At training steps 7300, training MLE loss is 2.686622804403305, train CL loss is 0.0068986060074530545\n",
      "At training steps 7350, training MLE loss is 2.6835068106651305, train CL loss is 0.006990306100342423\n",
      "At training steps 7400, training MLE loss is 2.683471364180247, train CL loss is 0.006984954710739354\n",
      "At training steps 7450, training MLE loss is 2.6832870987057684, train CL loss is 0.006945973748224787\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "- | #                                                 | 2 Elapsed Time: 0:00:00"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At training steps 7500, training MLE loss is 2.6826825110912322, train CL loss is 0.006924067175481469\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "| |                   #                             | 156 Elapsed Time: 0:00:07\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At training steps 7500, training MLE loss is 2.6826825110912322, train CL loss is 0.006924067175481469, validation loss is 2.6815046929375077\n",
      "Saving model...\n",
      "Model Saved!\n",
      "-----------------------------------\n",
      "At training steps 7550, training MLE loss is 2.679696134328842, train CL loss is 0.0068370223883539435\n",
      "At training steps 7600, training MLE loss is 2.678505402803421, train CL loss is 0.0068028295726981014\n",
      "At training steps 7650, training MLE loss is 2.6779031519095104, train CL loss is 0.0068749887892045084\n",
      "At training steps 7700, training MLE loss is 2.678090518116951, train CL loss is 0.00686251794337295\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "- | #                                                 | 2 Elapsed Time: 0:00:00"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At training steps 7750, training MLE loss is 2.6753330018520356, train CL loss is 0.006844049559906125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "| |                   #                             | 156 Elapsed Time: 0:00:07\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At training steps 7750, training MLE loss is 2.6753330018520356, train CL loss is 0.006844049559906125, validation loss is 2.6803381983083696\n",
      "Saving model...\n",
      "Model Saved!\n",
      "-----------------------------------\n",
      "At training steps 7800, training MLE loss is 2.6793985772132873, train CL loss is 0.006842949276324362\n",
      "At training steps 7850, training MLE loss is 2.676744274497032, train CL loss is 0.006871595360571518\n",
      "At training steps 7900, training MLE loss is 2.6721334167321524, train CL loss is 0.006833014882480105\n",
      "At training steps 7950, training MLE loss is 2.670359828770161, train CL loss is 0.006812825946835801\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "- | #                                                 | 2 Elapsed Time: 0:00:00"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At training steps 8000, training MLE loss is 2.6726896686553956, train CL loss is 0.006783379358705133\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "| |                   #                             | 156 Elapsed Time: 0:00:07\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At training steps 8000, training MLE loss is 2.6726896686553956, train CL loss is 0.006783379358705133, validation loss is 2.677836619589841\n",
      "Saving model...\n",
      "Model Saved!\n",
      "-----------------------------------\n",
      "At training steps 8050, training MLE loss is 2.66305428981781, train CL loss is 0.006752924325410276\n",
      "At training steps 8100, training MLE loss is 2.6742436987161637, train CL loss is 0.006801505006151274\n",
      "At training steps 8150, training MLE loss is 2.6822131260236106, train CL loss is 0.006793888483662159\n",
      "At training steps 8200, training MLE loss is 2.6802688524127007, train CL loss is 0.006774348297622055\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "- | #                                                 | 2 Elapsed Time: 0:00:00"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At training steps 8250, training MLE loss is 2.6818629739284514, train CL loss is 0.006778350699692965\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "| |                #                                | 156 Elapsed Time: 0:00:08\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At training steps 8250, training MLE loss is 2.6818629739284514, train CL loss is 0.006778350699692965, validation loss is 2.675888604726993\n",
      "Saving model...\n",
      "Model Saved!\n",
      "-----------------------------------\n",
      "At training steps 8300, training MLE loss is 2.6745682525634766, train CL loss is 0.006826460189186037\n",
      "At training steps 8350, training MLE loss is 2.671733195185661, train CL loss is 0.006803471056045964\n",
      "At training steps 8400, training MLE loss is 2.672587177356084, train CL loss is 0.006723214100735883\n",
      "At training steps 8450, training MLE loss is 2.6755725434422493, train CL loss is 0.0067103329644305635\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "- | #                                                 | 2 Elapsed Time: 0:00:00"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At training steps 8500, training MLE loss is 2.6733955483436587, train CL loss is 0.006700434208381921\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "| |                   #                             | 156 Elapsed Time: 0:00:07\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At training steps 8500, training MLE loss is 2.6733955483436587, train CL loss is 0.006700434208381921, validation loss is 2.6761338728011506\n",
      "At training steps 8550, training MLE loss is 2.6646924662590026, train CL loss is 0.0067426470876671375\n",
      "At training steps 8600, training MLE loss is 2.658109104037285, train CL loss is 0.006699946301523596\n",
      "At training steps 8650, training MLE loss is 2.6641476531823476, train CL loss is 0.006679333227220923\n",
      "At training steps 8700, training MLE loss is 2.667198656499386, train CL loss is 0.00668180781067349\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "- | #                                                 | 1 Elapsed Time: 0:00:00"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At training steps 8750, training MLE loss is 2.6683516635894775, train CL loss is 0.006659991087857634\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "| |                  #                              | 156 Elapsed Time: 0:00:07\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At training steps 8750, training MLE loss is 2.6683516635894775, train CL loss is 0.006659991087857634, validation loss is 2.675668699028032\n",
      "Saving model...\n",
      "Model Saved!\n",
      "-----------------------------------\n",
      "At training steps 8800, training MLE loss is 2.669468712806702, train CL loss is 0.006690655197016895\n",
      "At training steps 8850, training MLE loss is 2.667125626206398, train CL loss is 0.006718238983303308\n",
      "At training steps 8900, training MLE loss is 2.665276377995809, train CL loss is 0.006697639558309068\n",
      "At training steps 8950, training MLE loss is 2.6636004745960236, train CL loss is 0.006668065211270005\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "- | #                                                 | 2 Elapsed Time: 0:00:00"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At training steps 9000, training MLE loss is 2.664371607542038, train CL loss is 0.0066620773035101595\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "| |                   #                             | 156 Elapsed Time: 0:00:07\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At training steps 9000, training MLE loss is 2.664371607542038, train CL loss is 0.0066620773035101595, validation loss is 2.675294747238678\n",
      "Saving model...\n",
      "Model Saved!\n",
      "-----------------------------------\n",
      "At training steps 9050, training MLE loss is 2.678348662853241, train CL loss is 0.00663479145616293\n",
      "At training steps 9100, training MLE loss is 2.670626400709152, train CL loss is 0.006611852102214471\n",
      "At training steps 9150, training MLE loss is 2.6707731624444326, train CL loss is 0.0066468972992151975\n",
      "At training steps 9200, training MLE loss is 2.669122249186039, train CL loss is 0.006637310994556174\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "- | #                                                 | 2 Elapsed Time: 0:00:00"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At training steps 9250, training MLE loss is 2.6708753933906557, train CL loss is 0.006639871266670525\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "| |                   #                             | 156 Elapsed Time: 0:00:07\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At training steps 9250, training MLE loss is 2.6708753933906557, train CL loss is 0.006639871266670525, validation loss is 2.674801402526794\n",
      "Saving model...\n",
      "Model Saved!\n",
      "-----------------------------------\n",
      "At training steps 9300, training MLE loss is 2.6660111927986145, train CL loss is 0.0066152511839754876\n",
      "At training steps 9350, training MLE loss is 2.6662564837932585, train CL loss is 0.006605266449041664\n",
      "At training steps 9400, training MLE loss is 2.6661556990941366, train CL loss is 0.006641763377313812\n",
      "At training steps 9450, training MLE loss is 2.6661161735653875, train CL loss is 0.006657623973442241\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "- | #                                                 | 2 Elapsed Time: 0:00:00"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At training steps 9500, training MLE loss is 2.6648020462989805, train CL loss is 0.0066555537143722174\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "| |                   #                             | 156 Elapsed Time: 0:00:07\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At training steps 9500, training MLE loss is 2.6648020462989805, train CL loss is 0.0066555537143722174, validation loss is 2.674671017578537\n",
      "Saving model...\n",
      "Model Saved!\n",
      "-----------------------------------\n",
      "At training steps 9550, training MLE loss is 2.6626900911331175, train CL loss is 0.0065420783450827\n",
      "At training steps 9600, training MLE loss is 2.670868725180626, train CL loss is 0.00654439213569276\n",
      "At training steps 9650, training MLE loss is 2.6693346655368804, train CL loss is 0.00658150012139231\n",
      "At training steps 9700, training MLE loss is 2.6698755019903184, train CL loss is 0.006601547127356753\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "- | #                                                 | 2 Elapsed Time: 0:00:00"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At training steps 9750, training MLE loss is 2.6700197575092317, train CL loss is 0.006612891255877912\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "| |                  #                              | 156 Elapsed Time: 0:00:07\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At training steps 9750, training MLE loss is 2.6700197575092317, train CL loss is 0.006612891255877912, validation loss is 2.6741667991385896\n",
      "Saving model...\n",
      "Model Saved!\n",
      "-----------------------------------\n",
      "At training steps 9800, training MLE loss is 2.665933403968811, train CL loss is 0.006658593823667616\n",
      "At training steps 9850, training MLE loss is 2.667837498784065, train CL loss is 0.0066038946725893765\n",
      "At training steps 9900, training MLE loss is 2.667009958823522, train CL loss is 0.006597098892088979\n",
      "At training steps 9950, training MLE loss is 2.665754587352276, train CL loss is 0.006580807988357264\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "- | #                                                 | 2 Elapsed Time: 0:00:00"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At training steps 10000, training MLE loss is 2.666631906032562, train CL loss is 0.006587718073045835\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "| |                   #                             | 156 Elapsed Time: 0:00:07\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At training steps 10000, training MLE loss is 2.666631906032562, train CL loss is 0.006587718073045835, validation loss is 2.674269430006514\n",
      "Training stage completed!\n",
      "############################################################\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.multiprocessing as mp\n",
    "import argparse, os\n",
    "import random\n",
    "import numpy as np\n",
    "import time\n",
    "import logging\n",
    "import progressbar\n",
    "\n",
    "import logging\n",
    "logging.getLogger('transformers.generation_utils').disabled = True\n",
    "import argparse\n",
    "if __name__ == '__main__':\n",
    "    if torch.cuda.is_available():\n",
    "        print ('Cuda is available.')\n",
    "    cuda_available = torch.cuda.is_available()\n",
    "    multi_gpu_training = False\n",
    "    if cuda_available:\n",
    "        if torch.cuda.device_count() > 1:\n",
    "            multi_gpu_training = True\n",
    "            print ('Using Multi-GPU training, number of GPU is {}'.format(torch.cuda.device_count()))\n",
    "        else:\n",
    "            print ('Using single GPU training.')\n",
    "    else:\n",
    "        pass\n",
    "    \n",
    "    device = torch.device('cuda')\n",
    "    model_name = args.model_name\n",
    "\n",
    "    sos_token, pad_token = r'<-start_of_text->', r'<-pad->'\n",
    "    add_eos_token_to_data = args.add_eos_token_to_data\n",
    "    if add_eos_token_to_data == 'True':\n",
    "        add_eos_token_to_data = True\n",
    "        print ('Add eos token to data!')\n",
    "    elif add_eos_token_to_data == 'False':\n",
    "        add_eos_token_to_data = False\n",
    "        print ('Do not add eos token to data!')\n",
    "    else:\n",
    "        raise Exception('Wrong eos configuration for data!!!')\n",
    "    print ('Loading data...')\n",
    "    #from dataclass import Data\n",
    "    data = Data(model_name, args.train_path, args.dev_path, args.test_path, args.max_len, \n",
    "        sos_token, pad_token, add_eos_token_to_data)\n",
    "    print ('Data loaded.')\n",
    "\n",
    "    #from trainer import model_training\n",
    "    print ('############################################################')\n",
    "    print ('Start Training...')\n",
    "    #from simctg import SimCTG\n",
    "    print ('Initializaing SimCTG model...')\n",
    "    model = SimCTG(model_name, sos_token, pad_token)\n",
    "    if cuda_available:\n",
    "        if multi_gpu_training:\n",
    "            model = nn.DataParallel(model) # multi-gpu training\n",
    "        else:\n",
    "            pass\n",
    "        model = model.to(device)\n",
    "    else:\n",
    "        pass\n",
    "    print ('Model loaded') \n",
    "    total_steps, print_every, save_every = args.total_steps, args.print_every, args.save_every\n",
    "    ckpt_save_path = args.save_path_prefix\n",
    "    model = model_training(args, data, model, total_steps, print_every, save_every, \n",
    "        ckpt_save_path, cuda_available, device)\n",
    "    print ('Training stage completed!')\n",
    "    print ('############################################################')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d1773a38",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-08T16:56:56.743554Z",
     "iopub.status.busy": "2023-03-08T16:56:56.742674Z",
     "iopub.status.idle": "2023-03-08T16:56:56.748166Z",
     "shell.execute_reply": "2023-03-08T16:56:56.747120Z"
    },
    "papermill": {
     "duration": 0.168351,
     "end_time": "2023-03-08T16:56:56.750343",
     "exception": false,
     "start_time": "2023-03-08T16:56:56.581992",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "mscoco_args = Args('gpt2', \"/kaggle/input/mscoco/mscoco_train.json\",\n",
    "           \"/kaggle/input/mscoco/mscoco_val.json\", \n",
    "           \"/kaggle/input/mscoco/mscoco_test.json\",\n",
    "           'True', 0.5, 64, 1, 32, 4, 128, 20000, 100, 500, 2e-5, \"/kaggle/working/mscoco\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8e7216b8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-08T16:56:57.066701Z",
     "iopub.status.busy": "2023-03-08T16:56:57.065696Z",
     "iopub.status.idle": "2023-03-08T18:46:22.146153Z",
     "shell.execute_reply": "2023-03-08T18:46:22.145133Z"
    },
    "papermill": {
     "duration": 6565.241027,
     "end_time": "2023-03-08T18:46:22.148409",
     "exception": false,
     "start_time": "2023-03-08T16:56:56.907382",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cuda is available.\n",
      "Using single GPU training.\n",
      "Add eos token to data!\n",
      "Loading data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/ |#                                             | 145000 Elapsed Time: 0:00:00"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Add token to the tokenizer.\n",
      "Original vocabulary size is 50257\n",
      "Vocabulary size after extension is 50258\n",
      "sos token is <-start_of_text->, sos token id is 50257\n",
      "Add token to the tokenizer.\n",
      "Original vocabulary size is 50258\n",
      "Vocabulary size after extension is 50259\n",
      "pad token is <-pad->, pad token id is 50258\n",
      "eos token is <|endoftext|>, eos token id is 50256\n",
      "Processing /kaggle/input/flickr30k/flickr30k/flickr30k/flickr30k_train.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "| |      #                                       | 144999 Elapsed Time: 0:00:17\n",
      "- | #                                               | 612 Elapsed Time: 0:00:00"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/flickr30k/flickr30k/flickr30k/flickr30k_train.json processed!\n",
      "Processing /kaggle/input/flickr30k/flickr30k/flickr30k/flickr30k_val.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "| |        #                                       | 5069 Elapsed Time: 0:00:00\n",
      "- | #                                               | 846 Elapsed Time: 0:00:00"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/flickr30k/flickr30k/flickr30k/flickr30k_val.json processed!\n",
      "Processing /kaggle/input/flickr30k/flickr30k/flickr30k/flickr30k_test.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "| |       #                                        | 4999 Elapsed Time: 0:00:00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/flickr30k/flickr30k/flickr30k/flickr30k_test.json processed!\n",
      "train number:145000, dev number:5070, test number:5000\n",
      "Data loaded.\n",
      "############################################################\n",
      "Start Training...\n",
      "Initializaing SimCTG model...\n",
      "Add token to the tokenizer.\n",
      "Original vocabulary size is 50257\n",
      "Vocabulary size after extension is 50258\n",
      "sos token is <-start_of_text->, sos token id is 50257\n",
      "Add token to the tokenizer.\n",
      "Original vocabulary size is 50258\n",
      "Vocabulary size after extension is 50259\n",
      "pad token is <-pad->, pad token id is 50258\n",
      "eos token is <|endoftext|>, eos token id is 50256\n",
      "Resizing model embedding...\n",
      "Model embedding resized!\n",
      "Model loaded\n",
      "total training steps is 10000, warmup steps is 1000\n",
      "--------------------------------------------------------------------------\n",
      "Start Training:\n",
      "At training steps 50, training MLE loss is 86.50591785430908, train CL loss is 0.4446336743235588\n",
      "At training steps 100, training MLE loss is 75.01354355812073, train CL loss is 0.43811935745179653\n",
      "At training steps 150, training MLE loss is 55.12694580793381, train CL loss is 0.3551487259318431\n",
      "At training steps 200, training MLE loss is 42.69362684547901, train CL loss is 0.32034625647589565\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "- | #                                                 | 2 Elapsed Time: 0:00:00"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At training steps 250, training MLE loss is 34.94899475622177, train CL loss is 0.29817717902362345\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "| |                   #                             | 156 Elapsed Time: 0:00:07\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At training steps 250, training MLE loss is 34.94899475622177, train CL loss is 0.29817717902362345, validation loss is 3.4792544365583056\n",
      "Saving model...\n",
      "Model Saved!\n",
      "-----------------------------------\n",
      "At training steps 300, training MLE loss is 3.5857187795639036, train CL loss is 0.1916647234559059\n",
      "At training steps 350, training MLE loss is 3.5094057750701904, train CL loss is 0.17686646677553652\n",
      "At training steps 400, training MLE loss is 3.4472061494986215, train CL loss is 0.1619758374368151\n",
      "At training steps 450, training MLE loss is 3.403219172358513, train CL loss is 0.14641440546140075\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "- | #                                                 | 2 Elapsed Time: 0:00:00"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At training steps 500, training MLE loss is 3.3667803025245666, train CL loss is 0.13067736952379347\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "| |                   #                             | 156 Elapsed Time: 0:00:07\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At training steps 500, training MLE loss is 3.3667803025245666, train CL loss is 0.13067736952379347, validation loss is 3.0542421535590325\n",
      "Saving model...\n",
      "Model Saved!\n",
      "-----------------------------------\n",
      "At training steps 550, training MLE loss is 3.1744389116764067, train CL loss is 0.0515899771079421\n",
      "At training steps 600, training MLE loss is 3.155550929903984, train CL loss is 0.045895846262574196\n",
      "At training steps 650, training MLE loss is 3.144946635961533, train CL loss is 0.04265876375138759\n",
      "At training steps 700, training MLE loss is 3.132600277066231, train CL loss is 0.04016605405369773\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "- | #                                                 | 2 Elapsed Time: 0:00:00"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At training steps 750, training MLE loss is 3.1126807606220246, train CL loss is 0.0382527774181217\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "| |                   #                             | 156 Elapsed Time: 0:00:07\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At training steps 750, training MLE loss is 3.1126807606220246, train CL loss is 0.0382527774181217, validation loss is 2.925877484746651\n",
      "Saving model...\n",
      "Model Saved!\n",
      "-----------------------------------\n",
      "At training steps 800, training MLE loss is 3.028925575017929, train CL loss is 0.02690190196968615\n",
      "At training steps 850, training MLE loss is 3.0285982376337053, train CL loss is 0.026746195470914245\n",
      "At training steps 900, training MLE loss is 3.0255375719070434, train CL loss is 0.025978145375847816\n",
      "At training steps 950, training MLE loss is 3.017245715856552, train CL loss is 0.025209908813703805\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "- | #                                                 | 2 Elapsed Time: 0:00:00"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At training steps 1000, training MLE loss is 3.0078969316482542, train CL loss is 0.024717320766299962\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "| |                   #                             | 156 Elapsed Time: 0:00:07\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At training steps 1000, training MLE loss is 3.0078969316482542, train CL loss is 0.024717320766299962, validation loss is 2.8660834319329602\n",
      "Saving model...\n",
      "Model Saved!\n",
      "-----------------------------------\n",
      "At training steps 1050, training MLE loss is 2.961170206069946, train CL loss is 0.021612802827730773\n",
      "At training steps 1100, training MLE loss is 2.958592136502266, train CL loss is 0.02094020222313702\n",
      "At training steps 1150, training MLE loss is 2.9552122008800508, train CL loss is 0.020452892795826\n",
      "At training steps 1200, training MLE loss is 2.950014791786671, train CL loss is 0.020040335555095226\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "- | #                                                 | 2 Elapsed Time: 0:00:00"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At training steps 1250, training MLE loss is 2.944648115634918, train CL loss is 0.01964418153744191\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "| |                   #                             | 156 Elapsed Time: 0:00:07\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At training steps 1250, training MLE loss is 2.944648115634918, train CL loss is 0.01964418153744191, validation loss is 2.8276752540126053\n",
      "Saving model...\n",
      "Model Saved!\n",
      "-----------------------------------\n",
      "At training steps 1300, training MLE loss is 2.916049538850784, train CL loss is 0.017631593863479792\n",
      "At training steps 1350, training MLE loss is 2.911668943762779, train CL loss is 0.01733106910251081\n",
      "At training steps 1400, training MLE loss is 2.903133350610733, train CL loss is 0.017097536966515083\n",
      "At training steps 1450, training MLE loss is 2.89981445223093, train CL loss is 0.016782381524099037\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "- | #                                                 | 2 Elapsed Time: 0:00:00"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At training steps 1500, training MLE loss is 2.8967087478637694, train CL loss is 0.01651110456418246\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "| |                  #                              | 156 Elapsed Time: 0:00:07\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At training steps 1500, training MLE loss is 2.8967087478637694, train CL loss is 0.01651110456418246, validation loss is 2.803403418298374\n",
      "Saving model...\n",
      "Model Saved!\n",
      "-----------------------------------\n",
      "At training steps 1550, training MLE loss is 2.8782851922512056, train CL loss is 0.01554420059081167\n",
      "At training steps 1600, training MLE loss is 2.8751578229665755, train CL loss is 0.015282964839134366\n",
      "At training steps 1650, training MLE loss is 2.8675374873479207, train CL loss is 0.015063471253961324\n",
      "At training steps 1700, training MLE loss is 2.8621054020524026, train CL loss is 0.0148641369282268\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "- | #                                                 | 2 Elapsed Time: 0:00:00"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At training steps 1750, training MLE loss is 2.860811891555786, train CL loss is 0.014784401901066304\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "| |                   #                             | 156 Elapsed Time: 0:00:07\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At training steps 1750, training MLE loss is 2.860811891555786, train CL loss is 0.014784401901066304, validation loss is 2.7839818905881235\n",
      "Saving model...\n",
      "Model Saved!\n",
      "-----------------------------------\n",
      "At training steps 1800, training MLE loss is 2.8624999356269836, train CL loss is 0.014060816918499768\n",
      "At training steps 1850, training MLE loss is 2.859174150824547, train CL loss is 0.01381904661655426\n",
      "At training steps 1900, training MLE loss is 2.8536959556738535, train CL loss is 0.013694726627630492\n",
      "At training steps 1950, training MLE loss is 2.850071816146374, train CL loss is 0.01355558654293418\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "- | #                                                 | 2 Elapsed Time: 0:00:00"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At training steps 2000, training MLE loss is 2.8461762821674346, train CL loss is 0.01345369351003319\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "| |                   #                             | 156 Elapsed Time: 0:00:07\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At training steps 2000, training MLE loss is 2.8461762821674346, train CL loss is 0.01345369351003319, validation loss is 2.7708700681108693\n",
      "Saving model...\n",
      "Model Saved!\n",
      "-----------------------------------\n",
      "At training steps 2050, training MLE loss is 2.8289731442928314, train CL loss is 0.01269469125661999\n",
      "At training steps 2100, training MLE loss is 2.8154546666145324, train CL loss is 0.012545929686166347\n",
      "At training steps 2150, training MLE loss is 2.818215719461441, train CL loss is 0.012539339436528584\n",
      "At training steps 2200, training MLE loss is 2.8187610748410226, train CL loss is 0.012405321571277455\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "- | #                                                 | 2 Elapsed Time: 0:00:00"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At training steps 2250, training MLE loss is 2.8151691653728483, train CL loss is 0.012260988851077854\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "| |                   #                             | 156 Elapsed Time: 0:00:07\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At training steps 2250, training MLE loss is 2.8151691653728483, train CL loss is 0.012260988851077854, validation loss is 2.7597519201754794\n",
      "Saving model...\n",
      "Model Saved!\n",
      "-----------------------------------\n",
      "At training steps 2300, training MLE loss is 2.816501452922821, train CL loss is 0.01173126363195479\n",
      "At training steps 2350, training MLE loss is 2.8119233506917953, train CL loss is 0.011630208005663008\n",
      "At training steps 2400, training MLE loss is 2.8118707211812337, train CL loss is 0.011585213906752566\n",
      "At training steps 2450, training MLE loss is 2.806650701165199, train CL loss is 0.0114550953253638\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "- | #                                                 | 2 Elapsed Time: 0:00:00"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At training steps 2500, training MLE loss is 2.8070769486427305, train CL loss is 0.011360606632195413\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "| |                   #                             | 156 Elapsed Time: 0:00:07\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At training steps 2500, training MLE loss is 2.8070769486427305, train CL loss is 0.011360606632195413, validation loss is 2.747862123020917\n",
      "Saving model...\n",
      "Model Saved!\n",
      "-----------------------------------\n",
      "At training steps 2550, training MLE loss is 2.779461292028427, train CL loss is 0.011100975787267089\n",
      "At training steps 2600, training MLE loss is 2.7957763344049456, train CL loss is 0.010922284710686654\n",
      "At training steps 2650, training MLE loss is 2.7873291170597074, train CL loss is 0.01088967251436164\n",
      "At training steps 2700, training MLE loss is 2.78712953299284, train CL loss is 0.01086031535291113\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "- | #                                                 | 2 Elapsed Time: 0:00:00"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At training steps 2750, training MLE loss is 2.7880057775974274, train CL loss is 0.010806973490398377\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "| |                  #                              | 156 Elapsed Time: 0:00:07\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At training steps 2750, training MLE loss is 2.7880057775974274, train CL loss is 0.010806973490398377, validation loss is 2.7365111580416093\n",
      "Saving model...\n",
      "Model Saved!\n",
      "-----------------------------------\n",
      "At training steps 2800, training MLE loss is 2.7852603936195375, train CL loss is 0.010284245694056154\n",
      "At training steps 2850, training MLE loss is 2.794443464875221, train CL loss is 0.010310928664403037\n",
      "At training steps 2900, training MLE loss is 2.7906944823265074, train CL loss is 0.010203764395943532\n",
      "At training steps 2950, training MLE loss is 2.78956950455904, train CL loss is 0.010124954935745336\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "- | #                                                 | 2 Elapsed Time: 0:00:00"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At training steps 3000, training MLE loss is 2.7881384513378142, train CL loss is 0.01006608795421198\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "| |                  #                              | 156 Elapsed Time: 0:00:07\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At training steps 3000, training MLE loss is 2.7881384513378142, train CL loss is 0.01006608795421198, validation loss is 2.7315297013854094\n",
      "Saving model...\n",
      "Model Saved!\n",
      "-----------------------------------\n",
      "At training steps 3050, training MLE loss is 2.7666773653030394, train CL loss is 0.009936242839321494\n",
      "At training steps 3100, training MLE loss is 2.7633174031972887, train CL loss is 0.009789401242742315\n",
      "At training steps 3150, training MLE loss is 2.764438907702764, train CL loss is 0.009759445186549177\n",
      "At training steps 3200, training MLE loss is 2.762897124886513, train CL loss is 0.00974587119766511\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "- | #                                                 | 2 Elapsed Time: 0:00:00"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At training steps 3250, training MLE loss is 2.763734133243561, train CL loss is 0.009713584505021572\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "| |                   #                             | 156 Elapsed Time: 0:00:07\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At training steps 3250, training MLE loss is 2.763734133243561, train CL loss is 0.009713584505021572, validation loss is 2.726212669667498\n",
      "Saving model...\n",
      "Model Saved!\n",
      "-----------------------------------\n",
      "At training steps 3300, training MLE loss is 2.755035563707352, train CL loss is 0.009461078885942697\n",
      "At training steps 3350, training MLE loss is 2.752248782515526, train CL loss is 0.009370006383396684\n",
      "At training steps 3400, training MLE loss is 2.7520154122511546, train CL loss is 0.009373502614131819\n",
      "At training steps 3450, training MLE loss is 2.7551573753356933, train CL loss is 0.009365768587449565\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "- | #                                                 | 2 Elapsed Time: 0:00:00"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At training steps 3500, training MLE loss is 2.7558072390556334, train CL loss is 0.009327884730882943\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "| |                   #                             | 156 Elapsed Time: 0:00:07\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At training steps 3500, training MLE loss is 2.7558072390556334, train CL loss is 0.009327884730882943, validation loss is 2.7215985175986237\n",
      "Saving model...\n",
      "Model Saved!\n",
      "-----------------------------------\n",
      "At training steps 3550, training MLE loss is 2.753508977890015, train CL loss is 0.009181281405035406\n",
      "At training steps 3600, training MLE loss is 2.7565709829330443, train CL loss is 0.00918081490905024\n",
      "At training steps 3650, training MLE loss is 2.754525634845098, train CL loss is 0.009176083499720942\n",
      "At training steps 3700, training MLE loss is 2.7531027778983117, train CL loss is 0.009101171916699968\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "- | #                                                 | 2 Elapsed Time: 0:00:00"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At training steps 3750, training MLE loss is 2.7522094061374665, train CL loss is 0.009067034141160548\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "| |                   #                             | 156 Elapsed Time: 0:00:07\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At training steps 3750, training MLE loss is 2.7522094061374665, train CL loss is 0.009067034141160548, validation loss is 2.7151759225955887\n",
      "Saving model...\n",
      "Model Saved!\n",
      "-----------------------------------\n",
      "At training steps 3800, training MLE loss is 2.7482115960121156, train CL loss is 0.008905627585481852\n",
      "At training steps 3850, training MLE loss is 2.7467210656404495, train CL loss is 0.00896376089542173\n",
      "At training steps 3900, training MLE loss is 2.7510768469174702, train CL loss is 0.008912856007615726\n",
      "At training steps 3950, training MLE loss is 2.748846605718136, train CL loss is 0.008795350362197496\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "- | #                                                 | 2 Elapsed Time: 0:00:00"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At training steps 4000, training MLE loss is 2.7438323862552645, train CL loss is 0.008747163327410818\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "| |                   #                             | 156 Elapsed Time: 0:00:07\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At training steps 4000, training MLE loss is 2.7438323862552645, train CL loss is 0.008747163327410818, validation loss is 2.7114607474640584\n",
      "Saving model...\n",
      "Model Saved!\n",
      "-----------------------------------\n",
      "At training steps 4050, training MLE loss is 2.746242731809616, train CL loss is 0.008390166303142906\n",
      "At training steps 4100, training MLE loss is 2.7347631359100344, train CL loss is 0.008494691347004845\n",
      "At training steps 4150, training MLE loss is 2.7359437771638233, train CL loss is 0.008525221251572172\n",
      "At training steps 4200, training MLE loss is 2.7392246437072756, train CL loss is 0.008496823219466022\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "- | #                                                 | 2 Elapsed Time: 0:00:00"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At training steps 4250, training MLE loss is 2.7374220113754273, train CL loss is 0.008500004099681973\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "| |                  #                              | 156 Elapsed Time: 0:00:07\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At training steps 4250, training MLE loss is 2.7374220113754273, train CL loss is 0.008500004099681973, validation loss is 2.7061526170417443\n",
      "Saving model...\n",
      "Model Saved!\n",
      "-----------------------------------\n",
      "At training steps 4300, training MLE loss is 2.7243010222911836, train CL loss is 0.00828922511311248\n",
      "At training steps 4350, training MLE loss is 2.7240605717897415, train CL loss is 0.008328378529986366\n",
      "At training steps 4400, training MLE loss is 2.7249705334504446, train CL loss is 0.008295924078362684\n",
      "At training steps 4450, training MLE loss is 2.727466923594475, train CL loss is 0.008340855198912322\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "- | #                                                 | 2 Elapsed Time: 0:00:00"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At training steps 4500, training MLE loss is 2.7279994122982023, train CL loss is 0.008336686646100133\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "| |                   #                             | 156 Elapsed Time: 0:00:07\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At training steps 4500, training MLE loss is 2.7279994122982023, train CL loss is 0.008336686646100133, validation loss is 2.7030625452717914\n",
      "Saving model...\n",
      "Model Saved!\n",
      "-----------------------------------\n",
      "At training steps 4550, training MLE loss is 2.72907369017601, train CL loss is 0.008102100456599147\n",
      "At training steps 4600, training MLE loss is 2.724970841407776, train CL loss is 0.008095431260298937\n",
      "At training steps 4650, training MLE loss is 2.7248940404256183, train CL loss is 0.008066758643835784\n",
      "At training steps 4700, training MLE loss is 2.7195638337731363, train CL loss is 0.008034166496945544\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "- | #                                                 | 2 Elapsed Time: 0:00:00"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At training steps 4750, training MLE loss is 2.7205360260009765, train CL loss is 0.0080276961424388\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "| |                   #                             | 156 Elapsed Time: 0:00:07\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At training steps 4750, training MLE loss is 2.7205360260009765, train CL loss is 0.0080276961424388, validation loss is 2.7011788601953515\n",
      "Saving model...\n",
      "Model Saved!\n",
      "-----------------------------------\n",
      "At training steps 4800, training MLE loss is 2.7310378730297087, train CL loss is 0.007933434240985662\n",
      "At training steps 4850, training MLE loss is 2.7308504515886307, train CL loss is 0.007920664568664505\n",
      "At training steps 4900, training MLE loss is 2.726236433585485, train CL loss is 0.007930505027373632\n",
      "At training steps 4950, training MLE loss is 2.7234598964452745, train CL loss is 0.00789984397822991\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "- | #                                                 | 2 Elapsed Time: 0:00:00"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At training steps 5000, training MLE loss is 2.720565677165985, train CL loss is 0.007912985518109053\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "| |                  #                              | 156 Elapsed Time: 0:00:07\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At training steps 5000, training MLE loss is 2.720565677165985, train CL loss is 0.007912985518109053, validation loss is 2.6979236070644905\n",
      "Saving model...\n",
      "Model Saved!\n",
      "-----------------------------------\n",
      "At training steps 5050, training MLE loss is 2.7233039700984953, train CL loss is 0.007857356497552245\n",
      "At training steps 5100, training MLE loss is 2.7164350187778474, train CL loss is 0.007786153551423922\n",
      "At training steps 5150, training MLE loss is 2.709970299402873, train CL loss is 0.0077495279310581585\n",
      "At training steps 5200, training MLE loss is 2.715164274573326, train CL loss is 0.007717715105391107\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "- | #                                                 | 2 Elapsed Time: 0:00:00"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At training steps 5250, training MLE loss is 2.7109481780529023, train CL loss is 0.007682757441885769\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "| |                  #                              | 156 Elapsed Time: 0:00:07\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At training steps 5250, training MLE loss is 2.7109481780529023, train CL loss is 0.007682757441885769, validation loss is 2.696627116984163\n",
      "Saving model...\n",
      "Model Saved!\n",
      "-----------------------------------\n",
      "At training steps 5300, training MLE loss is 2.7160015153884887, train CL loss is 0.007680256415624171\n",
      "At training steps 5350, training MLE loss is 2.7108998382091523, train CL loss is 0.007588859628885985\n",
      "At training steps 5400, training MLE loss is 2.7147406510512035, train CL loss is 0.007616754143188397\n",
      "At training steps 5450, training MLE loss is 2.717227800190449, train CL loss is 0.0076073903142241765\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "- | #                                                 | 2 Elapsed Time: 0:00:00"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At training steps 5500, training MLE loss is 2.716736418247223, train CL loss is 0.0075903131030499935\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "| |                   #                             | 156 Elapsed Time: 0:00:07\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At training steps 5500, training MLE loss is 2.716736418247223, train CL loss is 0.0075903131030499935, validation loss is 2.6939708194075793\n",
      "Saving model...\n",
      "Model Saved!\n",
      "-----------------------------------\n",
      "At training steps 5550, training MLE loss is 2.7168583488464355, train CL loss is 0.007517939535900951\n",
      "At training steps 5600, training MLE loss is 2.7089650893211363, train CL loss is 0.007528452008264139\n",
      "At training steps 5650, training MLE loss is 2.7060008605321246, train CL loss is 0.007516814654227346\n",
      "At training steps 5700, training MLE loss is 2.7038873633742333, train CL loss is 0.0074979206558782605\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "- | #                                                 | 2 Elapsed Time: 0:00:00"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At training steps 5750, training MLE loss is 2.701066177368164, train CL loss is 0.007484365808777511\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "| |                   #                             | 156 Elapsed Time: 0:00:07\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At training steps 5750, training MLE loss is 2.701066177368164, train CL loss is 0.007484365808777511, validation loss is 2.6913580465188516\n",
      "Saving model...\n",
      "Model Saved!\n",
      "-----------------------------------\n",
      "At training steps 5800, training MLE loss is 2.6962998032569887, train CL loss is 0.007456042733974755\n",
      "At training steps 5850, training MLE loss is 2.699984254837036, train CL loss is 0.007408129593823105\n",
      "At training steps 5900, training MLE loss is 2.698524075349172, train CL loss is 0.007360100579292824\n",
      "At training steps 5950, training MLE loss is 2.697005010843277, train CL loss is 0.0073403760086512195\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "- | #                                                 | 2 Elapsed Time: 0:00:00"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At training steps 6000, training MLE loss is 2.697796677827835, train CL loss is 0.007318161675706506\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "| |                   #                             | 156 Elapsed Time: 0:00:07\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At training steps 6000, training MLE loss is 2.697796677827835, train CL loss is 0.007318161675706506, validation loss is 2.690002708581925\n",
      "Saving model...\n",
      "Model Saved!\n",
      "-----------------------------------\n",
      "At training steps 6050, training MLE loss is 2.7084562945365906, train CL loss is 0.007310065622441471\n",
      "At training steps 6100, training MLE loss is 2.6991971349716186, train CL loss is 0.007285958213033155\n",
      "At training steps 6150, training MLE loss is 2.6923939259847005, train CL loss is 0.007301216734728466\n",
      "At training steps 6200, training MLE loss is 2.6883799889683724, train CL loss is 0.0072897862328682094\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "- | #                                                 | 2 Elapsed Time: 0:00:00"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At training steps 6250, training MLE loss is 2.690589182138443, train CL loss is 0.007271432145033032\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "| |                   #                             | 156 Elapsed Time: 0:00:07\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At training steps 6250, training MLE loss is 2.690589182138443, train CL loss is 0.007271432145033032, validation loss is 2.6882229958850052\n",
      "Saving model...\n",
      "Model Saved!\n",
      "-----------------------------------\n",
      "At training steps 6300, training MLE loss is 2.698529943227768, train CL loss is 0.0070693565532565115\n",
      "At training steps 6350, training MLE loss is 2.6940562123060228, train CL loss is 0.007080130157992244\n",
      "At training steps 6400, training MLE loss is 2.6864104489485423, train CL loss is 0.007081187727550666\n",
      "At training steps 6450, training MLE loss is 2.686900497972965, train CL loss is 0.00707276746223215\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "- | #                                                 | 2 Elapsed Time: 0:00:00"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At training steps 6500, training MLE loss is 2.686302544593811, train CL loss is 0.007060623284894973\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "| |                   #                             | 156 Elapsed Time: 0:00:07\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At training steps 6500, training MLE loss is 2.686302544593811, train CL loss is 0.007060623284894973, validation loss is 2.686125824568512\n",
      "Saving model...\n",
      "Model Saved!\n",
      "-----------------------------------\n",
      "At training steps 6550, training MLE loss is 2.682853181362152, train CL loss is 0.007050684948917478\n",
      "At training steps 6600, training MLE loss is 2.682671811580658, train CL loss is 0.0070226785179693255\n",
      "At training steps 6650, training MLE loss is 2.681231427192688, train CL loss is 0.0070113495543288685\n",
      "At training steps 6700, training MLE loss is 2.6826431468129157, train CL loss is 0.00699934852833394\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "- | #                                                 | 2 Elapsed Time: 0:00:00"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At training steps 6750, training MLE loss is 2.6820868053436278, train CL loss is 0.006981830241624266\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "| |                   #                             | 156 Elapsed Time: 0:00:07\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At training steps 6750, training MLE loss is 2.6820868053436278, train CL loss is 0.006981830241624266, validation loss is 2.6843514497518655\n",
      "Saving model...\n",
      "Model Saved!\n",
      "-----------------------------------\n",
      "At training steps 6800, training MLE loss is 2.6880186462402342, train CL loss is 0.0070018356060609225\n",
      "At training steps 6850, training MLE loss is 2.6907732135057447, train CL loss is 0.00698815580108203\n",
      "At training steps 6900, training MLE loss is 2.687016803026199, train CL loss is 0.006974850055606415\n",
      "At training steps 6950, training MLE loss is 2.68310869961977, train CL loss is 0.006988698901841417\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "- | #                                                 | 2 Elapsed Time: 0:00:00"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At training steps 7000, training MLE loss is 2.684938769340515, train CL loss is 0.007025787631049752\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "| |                   #                             | 156 Elapsed Time: 0:00:07\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At training steps 7000, training MLE loss is 2.684938769340515, train CL loss is 0.007025787631049752, validation loss is 2.6825598243997857\n",
      "Saving model...\n",
      "Model Saved!\n",
      "-----------------------------------\n",
      "At training steps 7050, training MLE loss is 2.6792464804649354, train CL loss is 0.007073643887415528\n",
      "At training steps 7100, training MLE loss is 2.678948495388031, train CL loss is 0.006961327136959881\n",
      "At training steps 7150, training MLE loss is 2.6853137771288553, train CL loss is 0.00695730972647046\n",
      "At training steps 7200, training MLE loss is 2.6830999937653544, train CL loss is 0.0069397627376019955\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "- | #                                                 | 2 Elapsed Time: 0:00:00"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At training steps 7250, training MLE loss is 2.682803137779236, train CL loss is 0.006931454594247043\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "| |                   #                             | 156 Elapsed Time: 0:00:07\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At training steps 7250, training MLE loss is 2.682803137779236, train CL loss is 0.006931454594247043, validation loss is 2.6804154161021\n",
      "Saving model...\n",
      "Model Saved!\n",
      "-----------------------------------\n",
      "At training steps 7300, training MLE loss is 2.691908274888992, train CL loss is 0.006833030369598418\n",
      "At training steps 7350, training MLE loss is 2.6842998921871186, train CL loss is 0.006877129827626049\n",
      "At training steps 7400, training MLE loss is 2.682914686203003, train CL loss is 0.006862838057180245\n",
      "At training steps 7450, training MLE loss is 2.684588363468647, train CL loss is 0.006913781462353654\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "- | #                                                 | 2 Elapsed Time: 0:00:00"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At training steps 7500, training MLE loss is 2.685162354707718, train CL loss is 0.006879777234978974\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "| |                  #                              | 156 Elapsed Time: 0:00:07\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At training steps 7500, training MLE loss is 2.685162354707718, train CL loss is 0.006879777234978974, validation loss is 2.67916139005439\n",
      "Saving model...\n",
      "Model Saved!\n",
      "-----------------------------------\n",
      "At training steps 7550, training MLE loss is 2.6916236090660095, train CL loss is 0.006728229899890721\n",
      "At training steps 7600, training MLE loss is 2.6864327430725097, train CL loss is 0.0067985605145804585\n",
      "At training steps 7650, training MLE loss is 2.685591219266256, train CL loss is 0.006809285698303332\n",
      "At training steps 7700, training MLE loss is 2.6828581312298776, train CL loss is 0.006806636044057086\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "- | #                                                 | 2 Elapsed Time: 0:00:00"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At training steps 7750, training MLE loss is 2.6837402241230013, train CL loss is 0.006803704244084656\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "| |                  #                              | 156 Elapsed Time: 0:00:07\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At training steps 7750, training MLE loss is 2.6837402241230013, train CL loss is 0.006803704244084656, validation loss is 2.6780675792799715\n",
      "Saving model...\n",
      "Model Saved!\n",
      "-----------------------------------\n",
      "At training steps 7800, training MLE loss is 2.6692636132240297, train CL loss is 0.006890996091533453\n",
      "At training steps 7850, training MLE loss is 2.678474935889244, train CL loss is 0.006838605671655387\n",
      "At training steps 7900, training MLE loss is 2.6713732139269513, train CL loss is 0.006789532968929659\n",
      "At training steps 7950, training MLE loss is 2.669508013129234, train CL loss is 0.006786242424859665\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "- | #                                                 | 2 Elapsed Time: 0:00:00"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At training steps 8000, training MLE loss is 2.6686993906497953, train CL loss is 0.006761864523403347\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "| |                   #                             | 156 Elapsed Time: 0:00:07\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At training steps 8000, training MLE loss is 2.6686993906497953, train CL loss is 0.006761864523403347, validation loss is 2.676811147041697\n",
      "Saving model...\n",
      "Model Saved!\n",
      "-----------------------------------\n",
      "At training steps 8050, training MLE loss is 2.6702385890483855, train CL loss is 0.00660444414941594\n",
      "At training steps 8100, training MLE loss is 2.6692964392900467, train CL loss is 0.006650283854687586\n",
      "At training steps 8150, training MLE loss is 2.670385706027349, train CL loss is 0.0066380651597864925\n",
      "At training steps 8200, training MLE loss is 2.6686617103219032, train CL loss is 0.006690542867290788\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "- | #                                                 | 2 Elapsed Time: 0:00:00"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At training steps 8250, training MLE loss is 2.668591616868973, train CL loss is 0.006703532222658396\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "| |                   #                             | 156 Elapsed Time: 0:00:07\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At training steps 8250, training MLE loss is 2.668591616868973, train CL loss is 0.006703532222658396, validation loss is 2.676940350622814\n",
      "At training steps 8300, training MLE loss is 2.676745672225952, train CL loss is 0.006726080882363022\n",
      "At training steps 8350, training MLE loss is 2.6757458204030993, train CL loss is 0.006748063814593479\n",
      "At training steps 8400, training MLE loss is 2.6736981507142383, train CL loss is 0.00667883758743604\n",
      "At training steps 8450, training MLE loss is 2.673828758597374, train CL loss is 0.00669326092407573\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "- | #                                                 | 2 Elapsed Time: 0:00:00"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At training steps 8500, training MLE loss is 2.673412171602249, train CL loss is 0.006692436147015542\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "| |                   #                             | 156 Elapsed Time: 0:00:07\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At training steps 8500, training MLE loss is 2.673412171602249, train CL loss is 0.006692436147015542, validation loss is 2.6761603924011066\n",
      "Saving model...\n",
      "Model Saved!\n",
      "-----------------------------------\n",
      "At training steps 8550, training MLE loss is 2.677997080087662, train CL loss is 0.006720739623997361\n",
      "At training steps 8600, training MLE loss is 2.681458113193512, train CL loss is 0.006668533170595765\n",
      "At training steps 8650, training MLE loss is 2.678089912732442, train CL loss is 0.006693617573473603\n",
      "At training steps 8700, training MLE loss is 2.6732740843296052, train CL loss is 0.006677523668040522\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "- | #                                                 | 2 Elapsed Time: 0:00:00"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At training steps 8750, training MLE loss is 2.6736988108158113, train CL loss is 0.00666866759583354\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "| |                   #                             | 156 Elapsed Time: 0:00:07\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At training steps 8750, training MLE loss is 2.6736988108158113, train CL loss is 0.00666866759583354, validation loss is 2.675207535304272\n",
      "Saving model...\n",
      "Model Saved!\n",
      "-----------------------------------\n",
      "At training steps 8800, training MLE loss is 2.6688389098644256, train CL loss is 0.006682146030943841\n",
      "At training steps 8850, training MLE loss is 2.6710133254528046, train CL loss is 0.006636038521537557\n",
      "At training steps 8900, training MLE loss is 2.6695152103900908, train CL loss is 0.006620200797139357\n",
      "At training steps 8950, training MLE loss is 2.670042479932308, train CL loss is 0.006621497492305934\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "- | #                                                 | 2 Elapsed Time: 0:00:00"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At training steps 9000, training MLE loss is 2.66966073346138, train CL loss is 0.00662111180415377\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "| |                 #                               | 156 Elapsed Time: 0:00:08\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At training steps 9000, training MLE loss is 2.66966073346138, train CL loss is 0.00662111180415377, validation loss is 2.6741736418938977\n",
      "Saving model...\n",
      "Model Saved!\n",
      "-----------------------------------\n",
      "At training steps 9050, training MLE loss is 2.6609369349479675, train CL loss is 0.006565530791413039\n",
      "At training steps 9100, training MLE loss is 2.666455587744713, train CL loss is 0.006559667466208338\n",
      "At training steps 9150, training MLE loss is 2.6699963327248892, train CL loss is 0.0065782606656042235\n",
      "At training steps 9200, training MLE loss is 2.6707584619522096, train CL loss is 0.006597354690311477\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "- | #                                                 | 2 Elapsed Time: 0:00:00"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At training steps 9250, training MLE loss is 2.672373213529587, train CL loss is 0.006606733935885132\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "| |                   #                             | 156 Elapsed Time: 0:00:07\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At training steps 9250, training MLE loss is 2.672373213529587, train CL loss is 0.006606733935885132, validation loss is 2.673926485885605\n",
      "Saving model...\n",
      "Model Saved!\n",
      "-----------------------------------\n",
      "At training steps 9300, training MLE loss is 2.663531507253647, train CL loss is 0.006547241010703146\n",
      "At training steps 9350, training MLE loss is 2.6617275673151015, train CL loss is 0.006509475170169025\n",
      "At training steps 9400, training MLE loss is 2.6589776253700257, train CL loss is 0.0065508868902300794\n",
      "At training steps 9450, training MLE loss is 2.660111123919487, train CL loss is 0.006566842932370491\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "- | #                                                 | 2 Elapsed Time: 0:00:00"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At training steps 9500, training MLE loss is 2.662328051328659, train CL loss is 0.006554687559138983\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "| |                   #                             | 156 Elapsed Time: 0:00:07\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At training steps 9500, training MLE loss is 2.662328051328659, train CL loss is 0.006554687559138983, validation loss is 2.673934584044686\n",
      "At training steps 9550, training MLE loss is 2.669171677827835, train CL loss is 0.006595007593277842\n",
      "At training steps 9600, training MLE loss is 2.6686159670352936, train CL loss is 0.006546075842343271\n",
      "At training steps 9650, training MLE loss is 2.6740362191200258, train CL loss is 0.006550703609827906\n",
      "At training steps 9700, training MLE loss is 2.670478744506836, train CL loss is 0.0065314780722837895\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "- | #                                                 | 2 Elapsed Time: 0:00:00"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At training steps 9750, training MLE loss is 2.6683958072662355, train CL loss is 0.006521219823509455\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "| |                   #                             | 156 Elapsed Time: 0:00:07\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At training steps 9750, training MLE loss is 2.6683958072662355, train CL loss is 0.006521219823509455, validation loss is 2.6733436984833796\n",
      "Saving model...\n",
      "Model Saved!\n",
      "-----------------------------------\n",
      "At training steps 9800, training MLE loss is 2.659423379898071, train CL loss is 0.006480978152249009\n",
      "At training steps 9850, training MLE loss is 2.6616420328617094, train CL loss is 0.006529177543707192\n",
      "At training steps 9900, training MLE loss is 2.6636938563982646, train CL loss is 0.006521945266673962\n",
      "At training steps 9950, training MLE loss is 2.6669489607214927, train CL loss is 0.006549172606319189\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "- | #                                                 | 2 Elapsed Time: 0:00:00"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At training steps 10000, training MLE loss is 2.6677763950824738, train CL loss is 0.006544685707893223\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "| |                   #                             | 156 Elapsed Time: 0:00:07\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At training steps 10000, training MLE loss is 2.6677763950824738, train CL loss is 0.006544685707893223, validation loss is 2.6732797284184375\n",
      "Saving model...\n",
      "Model Saved!\n",
      "-----------------------------------\n",
      "Training stage completed!\n",
      "############################################################\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.multiprocessing as mp\n",
    "import argparse, os\n",
    "import random\n",
    "import numpy as np\n",
    "import time\n",
    "import logging\n",
    "import progressbar\n",
    "\n",
    "import logging\n",
    "logging.getLogger('transformers.generation_utils').disabled = True\n",
    "import argparse\n",
    "if __name__ == '__main__':\n",
    "    if torch.cuda.is_available():\n",
    "        print ('Cuda is available.')\n",
    "    cuda_available = torch.cuda.is_available()\n",
    "    multi_gpu_training = False\n",
    "    if cuda_available:\n",
    "        if torch.cuda.device_count() > 1:\n",
    "            multi_gpu_training = True\n",
    "            print ('Using Multi-GPU training, number of GPU is {}'.format(torch.cuda.device_count()))\n",
    "        else:\n",
    "            print ('Using single GPU training.')\n",
    "    else:\n",
    "        pass\n",
    "    \n",
    "    device = torch.device('cuda')\n",
    "    model_name = args.model_name\n",
    "\n",
    "    sos_token, pad_token = r'<-start_of_text->', r'<-pad->'\n",
    "    add_eos_token_to_data = args.add_eos_token_to_data\n",
    "    if add_eos_token_to_data == 'True':\n",
    "        add_eos_token_to_data = True\n",
    "        print ('Add eos token to data!')\n",
    "    elif add_eos_token_to_data == 'False':\n",
    "        add_eos_token_to_data = False\n",
    "        print ('Do not add eos token to data!')\n",
    "    else:\n",
    "        raise Exception('Wrong eos configuration for data!!!')\n",
    "    print ('Loading data...')\n",
    "    #from dataclass import Data\n",
    "    data = Data(model_name, args.train_path, args.dev_path, args.test_path, args.max_len, \n",
    "        sos_token, pad_token, add_eos_token_to_data)\n",
    "    print ('Data loaded.')\n",
    "\n",
    "    #from trainer import model_training\n",
    "    print ('############################################################')\n",
    "    print ('Start Training...')\n",
    "    #from simctg import SimCTG\n",
    "    print ('Initializaing SimCTG model...')\n",
    "    model = SimCTG(model_name, sos_token, pad_token)\n",
    "    if cuda_available:\n",
    "        if multi_gpu_training:\n",
    "            model = nn.DataParallel(model) # multi-gpu training\n",
    "        else:\n",
    "            pass\n",
    "        model = model.to(device)\n",
    "    else:\n",
    "        pass\n",
    "    print ('Model loaded') \n",
    "    total_steps, print_every, save_every = args.total_steps, args.print_every, args.save_every\n",
    "    ckpt_save_path = args.save_path_prefix\n",
    "    model = model_training(args, data, model, total_steps, print_every, save_every, \n",
    "        ckpt_save_path, cuda_available, device)\n",
    "    print ('Training stage completed!')\n",
    "    print ('############################################################')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 13149.096158,
   "end_time": "2023-03-08T18:46:26.280956",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2023-03-08T15:07:17.184798",
   "version": "2.4.0"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "01f09e97dc014aed876b048785bd1879": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_654080e54cc04082a22473b0055274a8",
        "IPY_MODEL_244b95f3fcd34934922e0f7a73b9b00e",
        "IPY_MODEL_bb09266f4f8045268a7813598ebf00bc"
       ],
       "layout": "IPY_MODEL_2709b40f5ded467b9130d9f9dd1918f5"
      }
     },
     "07a59f776a3640e4829cd112f5415991": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "083908c500a348198f2dcd4d2cb53e78": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_89f095d76e614d3bb5c531a0a20e2c08",
       "max": 548118077.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_e8d78f76e74a4a3788001ff0d7983620",
       "value": 548118077.0
      }
     },
     "0a4676fc44ff4ae3a5ffb0171f583f0b": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_d8bfbf8db46c483aba8cf9d972b3d57d",
       "placeholder": "",
       "style": "IPY_MODEL_20e2addda2eb4c658b8c58084d78dbb3",
       "value": " 456k/456k [00:00&lt;00:00, 1.83MB/s]"
      }
     },
     "0bdd1e4469834d609780bedc4ed49e42": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_1a58f987e86b466fa680f1fd846b9d7e",
        "IPY_MODEL_64d506657af74675bdf524ad45f24dd6",
        "IPY_MODEL_0a4676fc44ff4ae3a5ffb0171f583f0b"
       ],
       "layout": "IPY_MODEL_80d8fb20ddfa4a2ba828affe2686fec6"
      }
     },
     "0d5cec9da1b3400bb045c88487c163af": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "16801947530740fdb0e907db60511161": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "18109abbd7ca448da5a4cd3071c1d0e6": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "1a58f987e86b466fa680f1fd846b9d7e": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_bbfd6e00496c450d8e05baa6640e80ac",
       "placeholder": "",
       "style": "IPY_MODEL_257d62021d7d4e73ade88142d37824d3",
       "value": "Downloading ()olve/main/merges.txt: 100%"
      }
     },
     "1e1d35431bdf426eabccfe675df5a284": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "20e2addda2eb4c658b8c58084d78dbb3": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "22386f4ac6f44439a221e61106aac3dc": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "244b95f3fcd34934922e0f7a73b9b00e": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_d4d26efb764743ad8205df4f6c135fda",
       "max": 665.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_b1df50ea812843e9a45b594ea93bdfbe",
       "value": 665.0
      }
     },
     "257d62021d7d4e73ade88142d37824d3": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "26082dfe93504591b0157c245faec0af": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "2709b40f5ded467b9130d9f9dd1918f5": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "3909ee93fb8d483ca137a4dbdcb40b2f": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_f873560bf2b343df8707d5c9fcccd331",
       "placeholder": "",
       "style": "IPY_MODEL_4b78c64e815049388272f14afdd4807c",
       "value": "Downloading ()neration_config.json: 100%"
      }
     },
     "3ba03bc71c274e5aad418411f9813784": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "47a225814aca42ea9cbba8a919b517e5": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "4aad0929eee14b14a4a24723d63a5e5d": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "4b78c64e815049388272f14afdd4807c": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "4cc773e44e97453d99d7466589946a80": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "560d1fa735de46589dcb15fc702cf7f2": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "59ab18fb441b4a4ea98f211aa693b9e6": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_b572cea83f964fe2967be26ba1191389",
        "IPY_MODEL_083908c500a348198f2dcd4d2cb53e78",
        "IPY_MODEL_5aaf6fca5db746ba8beaa475eceef98c"
       ],
       "layout": "IPY_MODEL_16801947530740fdb0e907db60511161"
      }
     },
     "5aaf6fca5db746ba8beaa475eceef98c": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_902bc914e674482985f131e023012c2b",
       "placeholder": "",
       "style": "IPY_MODEL_6804edb3c651482fa5433c70508cc214",
       "value": " 548M/548M [00:02&lt;00:00, 292MB/s]"
      }
     },
     "5caeeb6e84444747bacfe5d2b326a01b": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "64d506657af74675bdf524ad45f24dd6": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_1e1d35431bdf426eabccfe675df5a284",
       "max": 456318.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_843c137d73aa4ef68e007c834457a906",
       "value": 456318.0
      }
     },
     "654080e54cc04082a22473b0055274a8": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_762f51724b6a4b9b995c5efdb4975a8c",
       "placeholder": "",
       "style": "IPY_MODEL_3ba03bc71c274e5aad418411f9813784",
       "value": "Downloading ()lve/main/config.json: 100%"
      }
     },
     "6804edb3c651482fa5433c70508cc214": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "75e98ddc841c4be495ffa7dc1dc49a89": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "762f51724b6a4b9b995c5efdb4975a8c": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "7c1bc736970d47a2b352288b944cdf6b": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_8bd9d910f2d548ff89beca2f75c60171",
       "max": 1355256.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_e711ffbf9aca4ef4b4232c2c331a9c71",
       "value": 1355256.0
      }
     },
     "80d8fb20ddfa4a2ba828affe2686fec6": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "843c137d73aa4ef68e007c834457a906": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "84a42b34ab7d44779cfcbb8611a5391c": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "89f095d76e614d3bb5c531a0a20e2c08": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "8a32677e3efd4a9694b59b42be41dc2c": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_75e98ddc841c4be495ffa7dc1dc49a89",
       "placeholder": "",
       "style": "IPY_MODEL_07a59f776a3640e4829cd112f5415991",
       "value": "Downloading ()olve/main/vocab.json: 100%"
      }
     },
     "8bd9d910f2d548ff89beca2f75c60171": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "902bc914e674482985f131e023012c2b": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "997302ab8191442eb6b707edf5fab0ed": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_18109abbd7ca448da5a4cd3071c1d0e6",
       "placeholder": "",
       "style": "IPY_MODEL_26082dfe93504591b0157c245faec0af",
       "value": " 1.36M/1.36M [00:00&lt;00:00, 4.16MB/s]"
      }
     },
     "a5bf347541b84bbd8eb700c993e47064": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_4cc773e44e97453d99d7466589946a80",
       "placeholder": "",
       "style": "IPY_MODEL_cfad1401a38344e384a20cf20a86cf42",
       "value": "Downloading ()/main/tokenizer.json: 100%"
      }
     },
     "aa5893b927154e1b9e730e26538c11c1": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_3909ee93fb8d483ca137a4dbdcb40b2f",
        "IPY_MODEL_d11700542a1645dd828b78419d8bb3ba",
        "IPY_MODEL_cc8bd1575fdf4d63bb1f1b85f14532cd"
       ],
       "layout": "IPY_MODEL_e6ac3b08b5cf4d3b93eb0909dc32fd28"
      }
     },
     "ae8ddd9653eb473bb9f24792c62744b4": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "b1df50ea812843e9a45b594ea93bdfbe": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "b572cea83f964fe2967be26ba1191389": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_ae8ddd9653eb473bb9f24792c62744b4",
       "placeholder": "",
       "style": "IPY_MODEL_bcfb8e05474446b7bf076de748185478",
       "value": "Downloading ()&quot;pytorch_model.bin&quot;;: 100%"
      }
     },
     "bb09266f4f8045268a7813598ebf00bc": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_e49c0a83e240498daa47b3472abb2df7",
       "placeholder": "",
       "style": "IPY_MODEL_4aad0929eee14b14a4a24723d63a5e5d",
       "value": " 665/665 [00:00&lt;00:00, 40.2kB/s]"
      }
     },
     "bbfd6e00496c450d8e05baa6640e80ac": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "bcfb8e05474446b7bf076de748185478": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "c3f75d1a677e45589628df45fdc36c21": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "c5374341d6cc472dbfa781d51f33827e": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "c6c04affd34b43e8873e8bfa06d4b14d": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_5caeeb6e84444747bacfe5d2b326a01b",
       "max": 1042301.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_0d5cec9da1b3400bb045c88487c163af",
       "value": 1042301.0
      }
     },
     "ca150cbcabf54f569f47fdd2cb58f84c": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "cc501d6cdc694355aeb8757a951d1587": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "cc8bd1575fdf4d63bb1f1b85f14532cd": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_cc501d6cdc694355aeb8757a951d1587",
       "placeholder": "",
       "style": "IPY_MODEL_c5374341d6cc472dbfa781d51f33827e",
       "value": " 124/124 [00:00&lt;00:00, 3.63kB/s]"
      }
     },
     "cfad1401a38344e384a20cf20a86cf42": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "d11700542a1645dd828b78419d8bb3ba": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_84a42b34ab7d44779cfcbb8611a5391c",
       "max": 124.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_560d1fa735de46589dcb15fc702cf7f2",
       "value": 124.0
      }
     },
     "d235cdf150fb49f89511c38fac46c418": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_8a32677e3efd4a9694b59b42be41dc2c",
        "IPY_MODEL_c6c04affd34b43e8873e8bfa06d4b14d",
        "IPY_MODEL_dadc4768651648be93bd92ece6267588"
       ],
       "layout": "IPY_MODEL_c3f75d1a677e45589628df45fdc36c21"
      }
     },
     "d4d26efb764743ad8205df4f6c135fda": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "d8bfbf8db46c483aba8cf9d972b3d57d": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "dadc4768651648be93bd92ece6267588": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_ca150cbcabf54f569f47fdd2cb58f84c",
       "placeholder": "",
       "style": "IPY_MODEL_22386f4ac6f44439a221e61106aac3dc",
       "value": " 1.04M/1.04M [00:00&lt;00:00, 3.37MB/s]"
      }
     },
     "e49c0a83e240498daa47b3472abb2df7": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "e6ac3b08b5cf4d3b93eb0909dc32fd28": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "e711ffbf9aca4ef4b4232c2c331a9c71": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "e8d78f76e74a4a3788001ff0d7983620": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "f873560bf2b343df8707d5c9fcccd331": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "fc78beccf37c4895a939deb837bd5e37": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_a5bf347541b84bbd8eb700c993e47064",
        "IPY_MODEL_7c1bc736970d47a2b352288b944cdf6b",
        "IPY_MODEL_997302ab8191442eb6b707edf5fab0ed"
       ],
       "layout": "IPY_MODEL_47a225814aca42ea9cbba8a919b517e5"
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
